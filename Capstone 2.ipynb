{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of NLP Project\n",
    "\n",
    "This project is designed to examine tweets created directly by a company's official Twitter account. I utilize tweet content to predict if a company beats the consensus earnings expectation each quarter. This project utilizes stock level data from CRSP and earnings announcemnet data from IBES in addition to the Twitter data. \n",
    "\n",
    "The primary challenge with this project is working with the Twitter data to determine if a tweet is considered financial or generic. Once I identify all tweets that are financial in topic, I use various machine learning algorithms to get the likelihood that a tweet is associated with an earnings beat (1) or an earnings miss (0). From this prediction, I retain the probability that a tweet is associated with a beat/miss for use in a 2nd model. This second model utilizes these probabilities as a single feature in the second model, allowing me to incorporate many other stock characteristics into the analysis.\n",
    "\n",
    "This project focuses on utilizing NLP in the field of finance and/or accounting. Although I do not have a large number of tweets (~1,400), this project is designed more for learning the techniques utilized when working with text than it is to provide a practical application for beating analyst recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I obtain daily stock level data from CRSP and import the data as a stata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21097755 entries, 0 to 21097754\n",
      "Data columns (total 10 columns):\n",
      "permno      float64\n",
      "date        datetime64[ns]\n",
      "shrcd       float64\n",
      "ticker      object\n",
      "primexch    object\n",
      "cusip       object\n",
      "prc         float64\n",
      "vol         float64\n",
      "ret         float64\n",
      "shrout      float64\n",
      "dtypes: datetime64[ns](1), float64(6), object(3)\n",
      "memory usage: 1.7+ GB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>date</th>\n",
       "      <th>shrcd</th>\n",
       "      <th>ticker</th>\n",
       "      <th>primexch</th>\n",
       "      <th>cusip</th>\n",
       "      <th>prc</th>\n",
       "      <th>vol</th>\n",
       "      <th>ret</th>\n",
       "      <th>shrout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>11.0</td>\n",
       "      <td>EWST</td>\n",
       "      <td>Q</td>\n",
       "      <td>36720410</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>4311.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>11.0</td>\n",
       "      <td>EWST</td>\n",
       "      <td>Q</td>\n",
       "      <td>36720410</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>0.023423</td>\n",
       "      <td>2959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>11.0</td>\n",
       "      <td>EWST</td>\n",
       "      <td>Q</td>\n",
       "      <td>36720410</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>510.0</td>\n",
       "      <td>-0.009683</td>\n",
       "      <td>2959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>11.0</td>\n",
       "      <td>EWST</td>\n",
       "      <td>Q</td>\n",
       "      <td>36720410</td>\n",
       "      <td>-11.344999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>2959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>11.0</td>\n",
       "      <td>EWST</td>\n",
       "      <td>Q</td>\n",
       "      <td>36720410</td>\n",
       "      <td>11.240000</td>\n",
       "      <td>600.0</td>\n",
       "      <td>-0.009255</td>\n",
       "      <td>2959.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    permno       date  shrcd ticker primexch     cusip        prc     vol  \\\n",
       "0  10001.0 2007-01-03   11.0   EWST        Q  36720410  11.100000  4311.0   \n",
       "1  10001.0 2007-01-04   11.0   EWST        Q  36720410  11.360000  4600.0   \n",
       "2  10001.0 2007-01-05   11.0   EWST        Q  36720410  11.250000   510.0   \n",
       "3  10001.0 2007-01-08   11.0   EWST        Q  36720410 -11.344999     0.0   \n",
       "4  10001.0 2007-01-09   11.0   EWST        Q  36720410  11.240000   600.0   \n",
       "\n",
       "        ret  shrout  \n",
       "0  0.000000  2959.0  \n",
       "1  0.023423  2959.0  \n",
       "2 -0.009683  2959.0  \n",
       "3  0.008444  2959.0  \n",
       "4 -0.009255  2959.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock = pd.read_stata('daily_stock.dta')\n",
    "print(stock.info())\n",
    "stock.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I clean the stock data based on the following characteristics\n",
    "    - share code = 10,11\n",
    "    - primary exchange = N, A, or Q\n",
    "    - absolute value price > 1\n",
    "    - volumne >= 0\n",
    "    - returns >= -1, convert B and C to NaN values\n",
    "    - shares outstanding > 0\n",
    "    \n",
    "    - drop all remaining missing observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11340601 entries, 0 to 21097754\n",
      "Data columns (total 7 columns):\n",
      "permno    float64\n",
      "date      datetime64[ns]\n",
      "ticker    object\n",
      "vol       float64\n",
      "ret       float64\n",
      "price     float64\n",
      "mcap      float64\n",
      "dtypes: datetime64[ns](1), float64(5), object(1)\n",
      "memory usage: 692.2+ MB\n"
     ]
    }
   ],
   "source": [
    "stock = stock.loc[(stock['shrcd'] == 10.0 ) | (stock['shrcd'] == 11.0)]\n",
    "stock = stock.loc[(stock['primexch'] == 'N') | (stock['primexch'] == 'A') | (stock['primexch'] == 'Q')]\n",
    "stock['price'] = stock['prc'].abs()\n",
    "stock = stock.loc[(stock['price'] >= 1)]\n",
    "stock = stock.loc[(stock['vol'] >= 0)]\n",
    "stock['ret'] = stock['ret'].replace(['B','C'], np.nan).apply(float)\n",
    "stock = stock.loc[(stock['ret'] >= -1)]\n",
    "stock = stock.loc[(stock['shrout'] > 0)]\n",
    "\n",
    "stock['mcap'] = stock['shrout'] * stock['price']\n",
    "\n",
    "stock.drop(columns = ['cusip','prc','shrcd','primexch','shrout'], inplace = True)\n",
    "stock = stock.dropna()\n",
    "\n",
    "stock.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I import Twitter data as a stata file. This data is already partially cleaned from a prior project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3439754 entries, 0 to 3439753\n",
      "Data columns (total 7 columns):\n",
      "twhandle         3439754 non-null object\n",
      "permno           3439754 non-null int32\n",
      "tweet_content    3439754 non-null object\n",
      "timestr          3439754 non-null object\n",
      "date             3439754 non-null datetime64[ns]\n",
      "time             3439754 non-null object\n",
      "tweet_id         3439754 non-null float32\n",
      "dtypes: datetime64[ns](1), float32(1), int32(1), object(4)\n",
      "memory usage: 183.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twhandle</th>\n",
       "      <th>permno</th>\n",
       "      <th>tweet_content</th>\n",
       "      <th>timestr</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2627058</th>\n",
       "      <td>SERVICENOW</td>\n",
       "      <td>13447</td>\n",
       "      <td>Don't be mistaken for a poser. Avoid this by remembering to wear your conference passes at all times! #NewsYouCanUse #Know14</td>\n",
       "      <td>10:30:02 PM</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td></td>\n",
       "      <td>2627059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601285</th>\n",
       "      <td>CHIPOTLETWEETS</td>\n",
       "      <td>91068</td>\n",
       "      <td>@nisa_ariÂ @tortillamaria @LMehalko If you can't enjoy lunch together, at least you can enjoy a burrito together, virtually. -Myra</td>\n",
       "      <td></td>\n",
       "      <td>2011-10-27</td>\n",
       "      <td>3:29 PM</td>\n",
       "      <td>601286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329542</th>\n",
       "      <td>HOMEAWAY</td>\n",
       "      <td>12882</td>\n",
       "      <td>@vanessapeters We're sorry to hear you are having difficulty, please email us with your info so we can move it forward social@homeaway.com</td>\n",
       "      <td>8:57:53 PM</td>\n",
       "      <td>2013-04-23</td>\n",
       "      <td></td>\n",
       "      <td>1329543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243359</th>\n",
       "      <td>GREENMTNCOFFEE</td>\n",
       "      <td>79588</td>\n",
       "      <td>@CowLoverJF We can't have that now, can we, Elizabeth? ;]</td>\n",
       "      <td></td>\n",
       "      <td>2013-09-06</td>\n",
       "      <td>1:30 PM</td>\n",
       "      <td>1243360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737556</th>\n",
       "      <td>MACYS</td>\n",
       "      <td>77462</td>\n",
       "      <td>@trangdhuynh We're glad an associate was able to help! What did you end up getting?</td>\n",
       "      <td></td>\n",
       "      <td>2012-10-22</td>\n",
       "      <td>1:40 PM</td>\n",
       "      <td>1737557.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               twhandle  permno  \\\n",
       "2627058      SERVICENOW   13447   \n",
       "601285   CHIPOTLETWEETS   91068   \n",
       "1329542        HOMEAWAY   12882   \n",
       "1243359  GREENMTNCOFFEE   79588   \n",
       "1737556           MACYS   77462   \n",
       "\n",
       "                                                                                                                                      tweet_content  \\\n",
       "2627058                Don't be mistaken for a poser. Avoid this by remembering to wear your conference passes at all times! #NewsYouCanUse #Know14   \n",
       "601285           @nisa_ariÂ @tortillamaria @LMehalko If you can't enjoy lunch together, at least you can enjoy a burrito together, virtually. -Myra   \n",
       "1329542  @vanessapeters We're sorry to hear you are having difficulty, please email us with your info so we can move it forward social@homeaway.com   \n",
       "1243359                                                                                   @CowLoverJF We can't have that now, can we, Elizabeth? ;]   \n",
       "1737556                                                         @trangdhuynh We're glad an associate was able to help! What did you end up getting?   \n",
       "\n",
       "             timestr       date     time   tweet_id  \n",
       "2627058  10:30:02 PM 2014-04-27           2627059.0  \n",
       "601285               2011-10-27  3:29 PM   601286.0  \n",
       "1329542   8:57:53 PM 2013-04-23           1329543.0  \n",
       "1243359              2013-09-06  1:30 PM  1243360.0  \n",
       "1737556              2012-10-22  1:40 PM  1737557.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_stata('Tweets_C2.dta')\n",
    "print(tweets.info(null_counts=True))\n",
    "tweets.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For practice working with text, I complete the following steps manually\n",
    "    - I identify time strings that have a PM attached to it\n",
    "    - I drop the AM and PM strings\n",
    "    - I create a variable for hour and minute from the time string\n",
    "    - I create a new 24 hour variable that adjusts 12 hour clocks based on if there was a PM attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>tweet_content</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hour_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87162</td>\n",
       "      <td>@AWESOMEDAPHY I'm sorry for the disappointment! We often run contests like this via FB or TW. Keep checking back after your birthday!-Stacey</td>\n",
       "      <td>2014-04-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>02:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87162</td>\n",
       "      <td>@ChitownFelice you should receive it shortly. Is there anything else I can help you with? Sheila</td>\n",
       "      <td>2014-05-06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87162</td>\n",
       "      <td>@HamptonsMPiece Send me your phone number in a private message, follow us, &amp; we will call you.--PJ</td>\n",
       "      <td>2014-05-17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87162</td>\n",
       "      <td>@monsour I am sorry for the inconvenience. Plz follow and DM me so I can check the status of your order. Thanks! AJ</td>\n",
       "      <td>2014-05-13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87162</td>\n",
       "      <td>@RemarkablyAvg I am sry we havnt heard back fr u re: the issue u posted. Pls reach out 2 us if u need any assistance, we r here 2 help.Thx!</td>\n",
       "      <td>2014-05-08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10:57:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno  \\\n",
       "0   87162   \n",
       "1   87162   \n",
       "2   87162   \n",
       "3   87162   \n",
       "4   87162   \n",
       "\n",
       "                                                                                                                                  tweet_content  \\\n",
       "0  @AWESOMEDAPHY I'm sorry for the disappointment! We often run contests like this via FB or TW. Keep checking back after your birthday!-Stacey   \n",
       "1                                              @ChitownFelice you should receive it shortly. Is there anything else I can help you with? Sheila   \n",
       "2                                            @HamptonsMPiece Send me your phone number in a private message, follow us, & we will call you.--PJ   \n",
       "3                           @monsour I am sorry for the inconvenience. Plz follow and DM me so I can check the status of your order. Thanks! AJ   \n",
       "4   @RemarkablyAvg I am sry we havnt heard back fr u re: the issue u posted. Pls reach out 2 us if u need any assistance, we r here 2 help.Thx!   \n",
       "\n",
       "        date  tweet_id   hour_24  \n",
       "0 2014-04-08       1.0  02:52:00  \n",
       "1 2014-05-06       2.0  12:54:00  \n",
       "2 2014-05-17       3.0  15:15:00  \n",
       "3 2014-05-13       4.0  18:58:00  \n",
       "4 2014-05-08       5.0  10:57:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['PM'] = tweets['timestr'].str.contains(r'\\bPM\\b',flags=re.IGNORECASE)\n",
    "tweets.loc[(tweets['timestr'] == ''), ['PM']] = tweets['time'].str.contains(r'\\bPM\\b',flags=re.IGNORECASE)\n",
    "\n",
    "tweets['timestr'] = tweets['timestr'].str.replace('PM','')\n",
    "tweets['timestr'] = tweets['timestr'].str.replace('AM','')\n",
    "tweets['time'] = tweets['time'].str.replace('PM','')\n",
    "tweets['time'] = tweets['time'].str.replace('AM','')\n",
    "\n",
    "tweets.loc[(tweets['time'] == ''), ['time']] = tweets['timestr']\n",
    "tweets['hour'] = tweets['time'].str.extract(r'([0-9]+)')\n",
    "tweets['minute'] = tweets['time'].str.extract(r'((?<=\\:)[0-9]+)')\n",
    "\n",
    "tweets[['hour','minute']] = tweets[['hour','minute']].apply(pd.to_numeric)\n",
    "\n",
    "tweets2 = tweets.copy(deep=True)\n",
    "tweets2.loc[(tweets2['PM'] == True), ['hour']] = tweets2['hour'] + 11\n",
    "tweets2['hour'] = tweets2['hour'].apply(str)\n",
    "tweets2['minute'] = tweets2['minute'].apply(str)\n",
    "tweets2['hour_24'] = pd.to_datetime(tweets2['hour'] + ':' + tweets2['minute'], format='%H:%M').dt.time\n",
    "\n",
    "tweets3 = tweets2.drop(columns = ['twhandle','timestr','time','PM','hour','minute']).copy(deep=True)\n",
    "tweets3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11340601 entries, 0 to 21097754\n",
      "Data columns (total 7 columns):\n",
      "permno    float64\n",
      "date      datetime64[ns]\n",
      "ticker    object\n",
      "vol       float64\n",
      "ret       float64\n",
      "price     float64\n",
      "mcap      float64\n",
      "dtypes: datetime64[ns](1), float64(5), object(1)\n",
      "memory usage: 692.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3439754 entries, 0 to 3439753\n",
      "Data columns (total 2 columns):\n",
      "permno    int32\n",
      "date      datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int32(1)\n",
      "memory usage: 65.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(stock.info())\n",
    "print(tweets3[['permno','date']].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I merge the stock data with the Twitter data while requiring information within both files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2734956 entries, 0 to 2734955\n",
      "Data columns (total 10 columns):\n",
      "permno           int32\n",
      "tweet_content    object\n",
      "date             datetime64[ns]\n",
      "tweet_id         float32\n",
      "hour_24          object\n",
      "ticker           object\n",
      "vol              float64\n",
      "ret              float64\n",
      "price            float64\n",
      "mcap             float64\n",
      "dtypes: datetime64[ns](1), float32(1), float64(4), int32(1), object(3)\n",
      "memory usage: 208.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1065"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets4 = pd.merge(tweets3, stock, left_on=['permno','date'], right_on=['permno','date'], how = 'inner')\n",
    "print(tweets4.info())\n",
    "tweets4['ticker'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a function that will allow me to determine if a tweet contains a cashtag of the company creating the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ticker(text,ticker):\n",
    "    x = '$'+ticker\n",
    "    if x.lower() in text.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2724359\n",
       "True       10597\n",
       "Name: cashtag_tweet, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets4['cashtag_tweet'] = tweets4.apply(lambda y: find_ticker(y['tweet_content'],y['ticker']),axis=1)\n",
    "tweets4['cashtag_tweet'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I identify all tweets that are considered financial by the following list of words\n",
    "    - earning\n",
    "    - conference call\n",
    "    - revenue\n",
    "    - quarterly\n",
    "    - CEO\n",
    "    - CFO\n",
    "    - financial\n",
    "    - finance\n",
    "    - fiscal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2685165\n",
       "True       49791\n",
       "Name: fin_tweet, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets4['fin_tweet'] = tweets4['tweet_content'].str.contains \\\n",
    "    (r'\\bearning|conference call|revenue|quarterly|CEO|CFO|financial|finance|fiscal' \\\n",
    "     ,flags=re.IGNORECASE)\n",
    "tweets4['fin_tweet'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I identify all tweets that contain a URL link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1655686\n",
       "False    1079270\n",
       "Name: url_tweet, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets4['url_tweet'] = tweets4['tweet_content'].str.contains(r'http')\n",
    "tweets4['url_tweet'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a new set of variables based on the classifications above\n",
    "    - financial_tweet = financial words + cashtags\n",
    "    - financial_url = financial_tweet + url_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2678100\n",
      "1      56856\n",
      "Name: financial_tweet, dtype: int64\n",
      "0    2690079\n",
      "1      44877\n",
      "Name: financial_url, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>tweet_content</th>\n",
       "      <th>date</th>\n",
       "      <th>hour_24</th>\n",
       "      <th>ticker</th>\n",
       "      <th>vol</th>\n",
       "      <th>ret</th>\n",
       "      <th>price</th>\n",
       "      <th>mcap</th>\n",
       "      <th>cashtag_tweet</th>\n",
       "      <th>fin_tweet</th>\n",
       "      <th>financial_tweet</th>\n",
       "      <th>financial_url</th>\n",
       "      <th>actual_dt_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87162</td>\n",
       "      <td>@AWESOMEDAPHY I'm sorry for the disappointment! We often run contests like this via FB or TW. Keep checking back after your birthday!-Stacey</td>\n",
       "      <td>2014-04-08</td>\n",
       "      <td>02:52:00</td>\n",
       "      <td>FLWS</td>\n",
       "      <td>107325.0</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>5.47</td>\n",
       "      <td>149790.474255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-08 02:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87162</td>\n",
       "      <td>@glehel We are following you please DM us your order details. Ty  Erika</td>\n",
       "      <td>2014-04-08</td>\n",
       "      <td>01:35:00</td>\n",
       "      <td>FLWS</td>\n",
       "      <td>107325.0</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>5.47</td>\n",
       "      <td>149790.474255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-08 01:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87162</td>\n",
       "      <td>@matthewdworkman I'm very sorry to hear about your frustration. Plz follow and DM me.  I will be happy to help you. Thanks! - Janet</td>\n",
       "      <td>2014-04-08</td>\n",
       "      <td>16:52:00</td>\n",
       "      <td>FLWS</td>\n",
       "      <td>107325.0</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>5.47</td>\n",
       "      <td>149790.474255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-08 16:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87162</td>\n",
       "      <td>@Kusand I am very sorry this. If I can assist with anything please DM me. - Janet</td>\n",
       "      <td>2014-04-08</td>\n",
       "      <td>20:04:00</td>\n",
       "      <td>FLWS</td>\n",
       "      <td>107325.0</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>5.47</td>\n",
       "      <td>149790.474255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-08 20:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87162</td>\n",
       "      <td>We've extended the Midnight Red's Roses #Sweepstakes! Enter to be one of the FIVE winners: http://t.co/pry4KGaZm0 @ItsMidnightRed</td>\n",
       "      <td>2014-04-08</td>\n",
       "      <td>16:29:00</td>\n",
       "      <td>FLWS</td>\n",
       "      <td>107325.0</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>5.47</td>\n",
       "      <td>149790.474255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-08 16:29:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno  \\\n",
       "0   87162   \n",
       "1   87162   \n",
       "2   87162   \n",
       "3   87162   \n",
       "4   87162   \n",
       "\n",
       "                                                                                                                                  tweet_content  \\\n",
       "0  @AWESOMEDAPHY I'm sorry for the disappointment! We often run contests like this via FB or TW. Keep checking back after your birthday!-Stacey   \n",
       "1                                                                       @glehel We are following you please DM us your order details. Ty  Erika   \n",
       "2           @matthewdworkman I'm very sorry to hear about your frustration. Plz follow and DM me.  I will be happy to help you. Thanks! - Janet   \n",
       "3                                                             @Kusand I am very sorry this. If I can assist with anything please DM me. - Janet   \n",
       "4             We've extended the Midnight Red's Roses #Sweepstakes! Enter to be one of the FIVE winners: http://t.co/pry4KGaZm0 @ItsMidnightRed   \n",
       "\n",
       "        date   hour_24 ticker       vol       ret  price           mcap  \\\n",
       "0 2014-04-08  02:52:00   FLWS  107325.0  0.012963   5.47  149790.474255   \n",
       "1 2014-04-08  01:35:00   FLWS  107325.0  0.012963   5.47  149790.474255   \n",
       "2 2014-04-08  16:52:00   FLWS  107325.0  0.012963   5.47  149790.474255   \n",
       "3 2014-04-08  20:04:00   FLWS  107325.0  0.012963   5.47  149790.474255   \n",
       "4 2014-04-08  16:29:00   FLWS  107325.0  0.012963   5.47  149790.474255   \n",
       "\n",
       "   cashtag_tweet  fin_tweet  financial_tweet  financial_url  \\\n",
       "0              0          0                0              0   \n",
       "1              0          0                0              0   \n",
       "2              0          0                0              0   \n",
       "3              0          0                0              0   \n",
       "4              0          0                0              0   \n",
       "\n",
       "          actual_dt_t  \n",
       "0 2014-04-08 02:52:00  \n",
       "1 2014-04-08 01:35:00  \n",
       "2 2014-04-08 16:52:00  \n",
       "3 2014-04-08 20:04:00  \n",
       "4 2014-04-08 16:29:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets5 = tweets4.copy(deep=True)\n",
    "\n",
    "tweets5['financial_tweet'] = (tweets5['fin_tweet'] | tweets5['cashtag_tweet']).astype(int)\n",
    "tweets5['financial_url'] = (tweets5['financial_tweet'] & tweets5['url_tweet']).astype(int)\n",
    "tweets5[['cashtag_tweet','fin_tweet','url_tweet']] = tweets5[['cashtag_tweet','fin_tweet','url_tweet']].astype(int)\n",
    "\n",
    "print(tweets5['financial_tweet'].value_counts())\n",
    "print(tweets5['financial_url'].value_counts())\n",
    "\n",
    "tweets5.drop(columns=['url_tweet','tweet_id'], inplace=True)\n",
    "\n",
    "tweets5['actual_dt_t'] = pd.to_datetime(tweets5['date'].apply(str) + ' ' + tweets5['hour_24'].apply(str))\n",
    "\n",
    "tweets5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain earnings data from IBES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1143331 entries, 0 to 1444462\n",
      "Data columns (total 10 columns):\n",
      "cusip          1143331 non-null object\n",
      "oftic          1143331 non-null object\n",
      "cname          1143331 non-null object\n",
      "numest         1143331 non-null float64\n",
      "meanest        1143331 non-null float64\n",
      "stdev          1143331 non-null float64\n",
      "fpedats        1143331 non-null datetime64[ns]\n",
      "actual         1143331 non-null float64\n",
      "anndats_act    1143331 non-null datetime64[ns]\n",
      "anntims_act    1143331 non-null object\n",
      "dtypes: datetime64[ns](2), float64(4), object(4)\n",
      "memory usage: 96.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "      <th>oftic</th>\n",
       "      <th>cname</th>\n",
       "      <th>numest</th>\n",
       "      <th>meanest</th>\n",
       "      <th>stdev</th>\n",
       "      <th>fpedats</th>\n",
       "      <th>actual</th>\n",
       "      <th>anndats_act</th>\n",
       "      <th>anntims_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2014-05-06</td>\n",
       "      <td>10:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2014-08-06</td>\n",
       "      <td>17:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2014-08-06</td>\n",
       "      <td>17:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2014-08-06</td>\n",
       "      <td>17:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2014-09-30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>16:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cusip oftic           cname  numest  meanest  stdev    fpedats  actual  \\\n",
       "0  87482X10  TLMR  TALMER BANCORP     4.0     0.08   0.01 2014-03-31    0.12   \n",
       "1  87482X10  TLMR  TALMER BANCORP     5.0     0.13   0.01 2014-06-30    0.27   \n",
       "2  87482X10  TLMR  TALMER BANCORP     5.0     0.13   0.01 2014-06-30    0.27   \n",
       "3  87482X10  TLMR  TALMER BANCORP     5.0     0.13   0.01 2014-06-30    0.27   \n",
       "4  87482X10  TLMR  TALMER BANCORP     5.0     0.25   0.05 2014-09-30    0.26   \n",
       "\n",
       "  anndats_act anntims_act  \n",
       "0  2014-05-06    10:45:00  \n",
       "1  2014-08-06    17:05:00  \n",
       "2  2014-08-06    17:05:00  \n",
       "3  2014-08-06    17:05:00  \n",
       "4  2014-11-04    16:15:00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibes = pd.read_stata('ibes_full.dta')\n",
    "ibes.drop(columns = ['ticker','measure','fpi'], inplace=True)\n",
    "ibes.dropna(inplace=True)\n",
    "print(ibes.info())\n",
    "ibes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I retain only the most recent observation for each company*earnings observation\n",
    "\n",
    "From the most recent observations, I calculate the following variables\n",
    "    - eps_surprise as the acutal earnings result - the expected earnings result\n",
    "    - eps_beat as a 1/0 if eps_surprise is positive\n",
    "    - earn_date as the actual date an earnings announcement occurs\n",
    "        - if an announcement occurs after 4:00pm, I assign the announcement date to the next day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oftic</th>\n",
       "      <th>numest</th>\n",
       "      <th>stdev</th>\n",
       "      <th>eps_surprise</th>\n",
       "      <th>eps_beat</th>\n",
       "      <th>earn_date</th>\n",
       "      <th>actual_dt_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.0214</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>2012-10-25 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>2014-01-27 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>2016-07-26 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-07-22</td>\n",
       "      <td>2008-07-21 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-22</td>\n",
       "      <td>2015-07-21 16:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    oftic  numest  stdev  eps_surprise  eps_beat  earn_date  \\\n",
       "428  AAPL    47.0   0.07       -0.0214         0 2012-10-26   \n",
       "433  AAPL    46.0   0.05        0.0614         1 2014-01-28   \n",
       "443  AAPL    37.0   0.04        0.0400         1 2016-07-27   \n",
       "411  AAPL    27.0   0.01        0.0200         1 2008-07-22   \n",
       "439  AAPL    39.0   0.10        0.0500         1 2015-07-22   \n",
       "\n",
       "            actual_dt_e  \n",
       "428 2012-10-25 16:30:00  \n",
       "433 2014-01-27 16:30:00  \n",
       "443 2016-07-26 16:30:00  \n",
       "411 2008-07-21 16:30:00  \n",
       "439 2015-07-21 16:30:00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "earn = ibes.groupby(['oftic','anndats_act'],as_index=False).last()\n",
    "\n",
    "earn['eps_surprise'] = earn['actual'] - earn['meanest']\n",
    "earn['eps_beat'] = np.where(earn['eps_surprise'] > 0, 1, 0)\n",
    "    \n",
    "earn['earn_date'] = earn['anndats_act']\n",
    "earn.loc[(earn['anntims_act'] >= '14:00'), ['earn_date']] = earn['anndats_act'] + timedelta(days=1)\n",
    "\n",
    "earn['actual_dt_e'] = pd.to_datetime(earn['anndats_act'].apply(str) + ' ' + earn['anntims_act'].apply(str))\n",
    "\n",
    "earn.drop(columns = ['meanest','actual','fpedats','cusip','cname','anndats_act','anntims_act'], inplace=True)\n",
    "earn[earn['oftic'] == 'AAPL'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 199960 entries, 0 to 199959\n",
      "Data columns (total 7 columns):\n",
      "oftic           199960 non-null object\n",
      "numest          199960 non-null float64\n",
      "stdev           199960 non-null float64\n",
      "eps_surprise    199960 non-null float64\n",
      "eps_beat        199960 non-null int32\n",
      "earn_date       199960 non-null datetime64[ns]\n",
      "actual_dt_e     199960 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(3), int32(1), object(1)\n",
      "memory usage: 16.4+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2734956 entries, 0 to 2734955\n",
      "Data columns (total 14 columns):\n",
      "permno             int32\n",
      "tweet_content      object\n",
      "date               datetime64[ns]\n",
      "hour_24            object\n",
      "ticker             object\n",
      "vol                float64\n",
      "ret                float64\n",
      "price              float64\n",
      "mcap               float64\n",
      "cashtag_tweet      int32\n",
      "fin_tweet          int32\n",
      "financial_tweet    int32\n",
      "financial_url      int32\n",
      "actual_dt_t        datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(4), int32(5), object(3)\n",
      "memory usage: 260.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(earn.info())\n",
    "print(tweets5.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I combine my Twitter data with IBES data where I want to keep all Tweets that occur over the earnings period (t-1, t=0), or the announcement date and the day prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87745 entries, 0 to 87744\n",
      "Data columns (total 21 columns):\n",
      "date               87745 non-null datetime64[ns]\n",
      "permno             87745 non-null int32\n",
      "tweet_content      87745 non-null object\n",
      "hour_24            87745 non-null object\n",
      "ticker             87745 non-null object\n",
      "vol                87745 non-null float64\n",
      "ret                87745 non-null float64\n",
      "price              87745 non-null float64\n",
      "mcap               87745 non-null float64\n",
      "cashtag_tweet      87745 non-null int32\n",
      "fin_tweet          87745 non-null int32\n",
      "financial_tweet    87745 non-null int32\n",
      "financial_url      87745 non-null int32\n",
      "actual_dt_t        87745 non-null datetime64[ns]\n",
      "oftic              87745 non-null object\n",
      "numest             87745 non-null float64\n",
      "stdev              87745 non-null float64\n",
      "eps_surprise       87745 non-null float64\n",
      "eps_beat           87745 non-null float64\n",
      "earn_date          87745 non-null datetime64[ns]\n",
      "actual_dt_e        87745 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](4), float64(8), int32(5), object(4)\n",
      "memory usage: 12.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>permno</th>\n",
       "      <th>tweet_content</th>\n",
       "      <th>hour_24</th>\n",
       "      <th>ticker</th>\n",
       "      <th>vol</th>\n",
       "      <th>ret</th>\n",
       "      <th>price</th>\n",
       "      <th>mcap</th>\n",
       "      <th>cashtag_tweet</th>\n",
       "      <th>...</th>\n",
       "      <th>financial_tweet</th>\n",
       "      <th>financial_url</th>\n",
       "      <th>actual_dt_t</th>\n",
       "      <th>oftic</th>\n",
       "      <th>numest</th>\n",
       "      <th>stdev</th>\n",
       "      <th>eps_surprise</th>\n",
       "      <th>eps_beat</th>\n",
       "      <th>earn_date</th>\n",
       "      <th>actual_dt_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-07-24</td>\n",
       "      <td>47466</td>\n",
       "      <td>President Again Seeks to Link Qaeda of Iraq to Qaeda of 9/11 http://tinyurl.com/2clvtr</td>\n",
       "      <td>18:09:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>857400.0</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>3.322341e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-07-24 18:09:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07-25</td>\n",
       "      <td>2007-07-25 08:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-07-24</td>\n",
       "      <td>47466</td>\n",
       "      <td>Libya Frees Foreign Medical Workers in H.I.V. Case http://tinyurl.com/2b6gz5</td>\n",
       "      <td>06:19:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>857400.0</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>3.322341e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-07-24 06:19:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07-25</td>\n",
       "      <td>2007-07-25 08:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-07-24</td>\n",
       "      <td>84788</td>\n",
       "      <td>$11.99 - Weeds - Season One http://amazon.com/goldbox</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>26366479.0</td>\n",
       "      <td>-0.034709</td>\n",
       "      <td>69.250000</td>\n",
       "      <td>2.862788e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-07-24 12:00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007-07-25</td>\n",
       "      <td>2007-07-24 16:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-07-24</td>\n",
       "      <td>47466</td>\n",
       "      <td>Blair Sees âSense of Possibilityâ in Mideast Talks http://tinyurl.com/2abfkw</td>\n",
       "      <td>09:08:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>857400.0</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>3.322341e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-07-24 09:08:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07-25</td>\n",
       "      <td>2007-07-25 08:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-07-24</td>\n",
       "      <td>47466</td>\n",
       "      <td>Libyaâs Release of 6 Prisoners Raises Criticism http://tinyurl.com/264akg</td>\n",
       "      <td>18:18:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>857400.0</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>3.322341e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-07-24 18:18:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07-25</td>\n",
       "      <td>2007-07-25 08:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  permno  \\\n",
       "0 2007-07-24   47466   \n",
       "1 2007-07-24   47466   \n",
       "2 2007-07-24   84788   \n",
       "3 2007-07-24   47466   \n",
       "4 2007-07-24   47466   \n",
       "\n",
       "                                                                            tweet_content  \\\n",
       "0  President Again Seeks to Link Qaeda of Iraq to Qaeda of 9/11 http://tinyurl.com/2clvtr   \n",
       "1            Libya Frees Foreign Medical Workers in H.I.V. Case http://tinyurl.com/2b6gz5   \n",
       "2                                   $11.99 - Weeds - Season One http://amazon.com/goldbox   \n",
       "3        Blair Sees âSense of Possibilityâ in Mideast Talks http://tinyurl.com/2abfkw   \n",
       "4             Libyaâs Release of 6 Prisoners Raises Criticism http://tinyurl.com/264akg   \n",
       "\n",
       "    hour_24 ticker         vol       ret      price          mcap  \\\n",
       "0  18:09:00    NYT    857400.0 -0.000430  23.219999  3.322341e+06   \n",
       "1  06:19:00    NYT    857400.0 -0.000430  23.219999  3.322341e+06   \n",
       "2  12:00:00   AMZN  26366479.0 -0.034709  69.250000  2.862788e+07   \n",
       "3  09:08:00    NYT    857400.0 -0.000430  23.219999  3.322341e+06   \n",
       "4  18:18:00    NYT    857400.0 -0.000430  23.219999  3.322341e+06   \n",
       "\n",
       "   cashtag_tweet  ...  financial_tweet  financial_url         actual_dt_t  \\\n",
       "0              0  ...                0              0 2007-07-24 18:09:00   \n",
       "1              0  ...                0              0 2007-07-24 06:19:00   \n",
       "2              0  ...                0              0 2007-07-24 12:00:00   \n",
       "3              0  ...                0              0 2007-07-24 09:08:00   \n",
       "4              0  ...                0              0 2007-07-24 18:18:00   \n",
       "\n",
       "  oftic numest  stdev  eps_surprise  eps_beat  earn_date         actual_dt_e  \n",
       "0   NYT   10.0   0.03         -0.02       0.0 2007-07-25 2007-07-25 08:35:00  \n",
       "1   NYT   10.0   0.03         -0.02       0.0 2007-07-25 2007-07-25 08:35:00  \n",
       "2  AMZN   21.0   0.03          0.04       1.0 2007-07-25 2007-07-24 16:01:00  \n",
       "3   NYT   10.0   0.03         -0.02       0.0 2007-07-25 2007-07-25 08:35:00  \n",
       "4   NYT   10.0   0.03         -0.02       0.0 2007-07-25 2007-07-25 08:35:00  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine earnings data with twitter/stock data to identify which dates are earnings dates\n",
    "\n",
    "full_sample = pd.merge_asof(tweets5.set_index('date').sort_index(), \\\n",
    "                            earn.set_index('earn_date',drop=False).sort_index(), \\\n",
    "                            left_by = ['ticker'], \\\n",
    "                            right_by = ['oftic'], \\\n",
    "                            left_index = True, \\\n",
    "                            right_index = True, \\\n",
    "                            tolerance = pd.Timedelta(days=1), \\\n",
    "                            direction = 'forward', \\\n",
    "                            )\n",
    "\n",
    "full_sample2 = full_sample.dropna()\n",
    "full_sample2.reset_index(inplace=True)\n",
    "print(full_sample2.info())\n",
    "full_sample2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I finalize my Twitter sample by removing all Tweets that occur on the same day as an earnings announcement but that occur after the actual time of the announcement. This results in a final sample that contains only tweets that occur on or before an earnings announcement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33393 entries, 0 to 87744\n",
      "Data columns (total 21 columns):\n",
      "date               33393 non-null datetime64[ns]\n",
      "permno             33393 non-null int32\n",
      "tweet_content      33393 non-null object\n",
      "hour_24            33393 non-null object\n",
      "ticker             33393 non-null object\n",
      "vol                33393 non-null float64\n",
      "ret                33393 non-null float64\n",
      "price              33393 non-null float64\n",
      "mcap               33393 non-null float64\n",
      "cashtag_tweet      33393 non-null int32\n",
      "fin_tweet          33393 non-null int32\n",
      "financial_tweet    33393 non-null int32\n",
      "financial_url      33393 non-null int32\n",
      "actual_dt_t        33393 non-null datetime64[ns]\n",
      "oftic              33393 non-null object\n",
      "numest             33393 non-null float64\n",
      "stdev              33393 non-null float64\n",
      "eps_surprise       33393 non-null float64\n",
      "eps_beat           33393 non-null float64\n",
      "earn_date          33393 non-null datetime64[ns]\n",
      "actual_dt_e        33393 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](4), float64(8), int32(5), object(4)\n",
      "memory usage: 5.0+ MB\n",
      "None\n",
      "0    31983\n",
      "1     1410\n",
      "Name: financial_tweet, dtype: int64\n",
      "863\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>permno</th>\n",
       "      <th>tweet_content</th>\n",
       "      <th>hour_24</th>\n",
       "      <th>ticker</th>\n",
       "      <th>vol</th>\n",
       "      <th>ret</th>\n",
       "      <th>price</th>\n",
       "      <th>mcap</th>\n",
       "      <th>cashtag_tweet</th>\n",
       "      <th>...</th>\n",
       "      <th>financial_tweet</th>\n",
       "      <th>financial_url</th>\n",
       "      <th>actual_dt_t</th>\n",
       "      <th>oftic</th>\n",
       "      <th>numest</th>\n",
       "      <th>stdev</th>\n",
       "      <th>eps_surprise</th>\n",
       "      <th>eps_beat</th>\n",
       "      <th>earn_date</th>\n",
       "      <th>actual_dt_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-07-24</td>\n",
       "      <td>47466</td>\n",
       "      <td>President Again Seeks to Link Qaeda of Iraq to Qaeda of 9/11 http://tinyurl.com/2clvtr</td>\n",
       "      <td>18:09:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>857400.0</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>3.322341e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-07-24 18:09:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07-25</td>\n",
       "      <td>2007-07-25 08:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-07-24</td>\n",
       "      <td>47466</td>\n",
       "      <td>Libya Frees Foreign Medical Workers in H.I.V. Case http://tinyurl.com/2b6gz5</td>\n",
       "      <td>06:19:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>857400.0</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>3.322341e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-07-24 06:19:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07-25</td>\n",
       "      <td>2007-07-25 08:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-07-24</td>\n",
       "      <td>84788</td>\n",
       "      <td>$11.99 - Weeds - Season One http://amazon.com/goldbox</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>26366479.0</td>\n",
       "      <td>-0.034709</td>\n",
       "      <td>69.250000</td>\n",
       "      <td>2.862788e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-07-24 12:00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007-07-25</td>\n",
       "      <td>2007-07-24 16:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-07-24</td>\n",
       "      <td>47466</td>\n",
       "      <td>Blair Sees âSense of Possibilityâ in Mideast Talks http://tinyurl.com/2abfkw</td>\n",
       "      <td>09:08:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>857400.0</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>3.322341e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-07-24 09:08:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07-25</td>\n",
       "      <td>2007-07-25 08:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-07-24</td>\n",
       "      <td>47466</td>\n",
       "      <td>Libyaâs Release of 6 Prisoners Raises Criticism http://tinyurl.com/264akg</td>\n",
       "      <td>18:18:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>857400.0</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>3.322341e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-07-24 18:18:00</td>\n",
       "      <td>NYT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07-25</td>\n",
       "      <td>2007-07-25 08:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  permno  \\\n",
       "0 2007-07-24   47466   \n",
       "1 2007-07-24   47466   \n",
       "2 2007-07-24   84788   \n",
       "3 2007-07-24   47466   \n",
       "4 2007-07-24   47466   \n",
       "\n",
       "                                                                            tweet_content  \\\n",
       "0  President Again Seeks to Link Qaeda of Iraq to Qaeda of 9/11 http://tinyurl.com/2clvtr   \n",
       "1            Libya Frees Foreign Medical Workers in H.I.V. Case http://tinyurl.com/2b6gz5   \n",
       "2                                   $11.99 - Weeds - Season One http://amazon.com/goldbox   \n",
       "3        Blair Sees âSense of Possibilityâ in Mideast Talks http://tinyurl.com/2abfkw   \n",
       "4             Libyaâs Release of 6 Prisoners Raises Criticism http://tinyurl.com/264akg   \n",
       "\n",
       "    hour_24 ticker         vol       ret      price          mcap  \\\n",
       "0  18:09:00    NYT    857400.0 -0.000430  23.219999  3.322341e+06   \n",
       "1  06:19:00    NYT    857400.0 -0.000430  23.219999  3.322341e+06   \n",
       "2  12:00:00   AMZN  26366479.0 -0.034709  69.250000  2.862788e+07   \n",
       "3  09:08:00    NYT    857400.0 -0.000430  23.219999  3.322341e+06   \n",
       "4  18:18:00    NYT    857400.0 -0.000430  23.219999  3.322341e+06   \n",
       "\n",
       "   cashtag_tweet  ...  financial_tweet  financial_url         actual_dt_t  \\\n",
       "0              0  ...                0              0 2007-07-24 18:09:00   \n",
       "1              0  ...                0              0 2007-07-24 06:19:00   \n",
       "2              0  ...                0              0 2007-07-24 12:00:00   \n",
       "3              0  ...                0              0 2007-07-24 09:08:00   \n",
       "4              0  ...                0              0 2007-07-24 18:18:00   \n",
       "\n",
       "  oftic numest  stdev  eps_surprise  eps_beat  earn_date         actual_dt_e  \n",
       "0   NYT   10.0   0.03         -0.02       0.0 2007-07-25 2007-07-25 08:35:00  \n",
       "1   NYT   10.0   0.03         -0.02       0.0 2007-07-25 2007-07-25 08:35:00  \n",
       "2  AMZN   21.0   0.03          0.04       1.0 2007-07-25 2007-07-24 16:01:00  \n",
       "3   NYT   10.0   0.03         -0.02       0.0 2007-07-25 2007-07-25 08:35:00  \n",
       "4   NYT   10.0   0.03         -0.02       0.0 2007-07-25 2007-07-25 08:35:00  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_sample3 = full_sample2.loc[(full_sample2['actual_dt_e'] > full_sample2['actual_dt_t'])]\n",
    "\n",
    "print(full_sample3.info())\n",
    "print(full_sample3['financial_tweet'].value_counts())\n",
    "print(full_sample3['ticker'].nunique())\n",
    "full_sample3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now proceed with the text cleaning. By waiting until a final sample is complete, I minimize the time it takes to work with the text. I first remove RT indicating a tweet is actually a retweet, I remove url links, I remove the # for hashtags, I remove cashtags, and I remove user IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jstar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Y'all can't expand cause contractions I'd think\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "full_sample4 = full_sample3.copy(deep=True)\n",
    "\n",
    "full_sample4['tweet_content'] = full_sample4['tweet_content'].str.replace \\\n",
    "(r'(^rt\\s?|http?\\S+\\s?|\\#\\s?|(\\$[a-z0-9]+\\s?)|\\@[a-z0-9]+\\s?)','',case=False).str.strip()\n",
    "full_sample4['tweet_content'] = full_sample4['tweet_content'].str.replace(r'(\\s?\\s+)',' ')\n",
    "\n",
    "full_sample4['tweet_content'][0] = \"Y'all can't expand cause contractions I'd think\"\n",
    "full_sample4['tweet_content'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now finalize preprocessing my text data for analysis with the following steps\n",
    "    - I remove accented characters\n",
    "    - I expland contractions such as the above I'm\n",
    "    - I remove special characters that may still remain\n",
    "    - I lemmative my text\n",
    "    - I remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import unicodedata\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load(parse=True, tag=True, entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', , stopwords , computer not'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "remove_stopwords(\"The, and, if are stopwords, computer is not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you all cannot expand contractions I would think you all because you are not smart'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contractions\n",
    "\n",
    "contractions.fix(\"Y'all can't expand contractions I'd think yall cause you're not smart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Accented text'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD',text).encode('ascii','ignore').decode('utf-8','ignore')\n",
    "    return text\n",
    "\n",
    "remove_accented_chars('Sómě Áccěntěd těxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun What do you think '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "remove_special_characters(\"Well this was fun! What do you think? 123#@!\", \n",
    "                          remove_digits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My system keep crash ! his crashed yesterday , ours crash daily'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "lemmatize_text(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "        # expand contractions    \n",
    "        if contraction_expansion:\n",
    "            doc = contractions.fix(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # lemmatize text\n",
    "        if text_lemmatization:\n",
    "            doc = lemmatize_text(doc)\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_content    Home Lenderâs Woes Fuel Marketâs Decline\n",
       "clean_text              home lendera woe fuel marketa decline\n",
       "Name: 7, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_sample4['clean_text'] = normalize_corpus(full_sample4['tweet_content'])\n",
    "\n",
    "full_sample4.iloc[7][['tweet_content', 'clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1410 entries, 382 to 87511\n",
      "Data columns (total 22 columns):\n",
      "date               1410 non-null datetime64[ns]\n",
      "permno             1410 non-null int32\n",
      "tweet_content      1410 non-null object\n",
      "hour_24            1410 non-null object\n",
      "ticker             1410 non-null object\n",
      "vol                1410 non-null float64\n",
      "ret                1410 non-null float64\n",
      "price              1410 non-null float64\n",
      "mcap               1410 non-null float64\n",
      "cashtag_tweet      1410 non-null int32\n",
      "fin_tweet          1410 non-null int32\n",
      "financial_tweet    1410 non-null int32\n",
      "financial_url      1410 non-null int32\n",
      "actual_dt_t        1410 non-null datetime64[ns]\n",
      "oftic              1410 non-null object\n",
      "numest             1410 non-null float64\n",
      "stdev              1410 non-null float64\n",
      "eps_surprise       1410 non-null float64\n",
      "eps_beat           1410 non-null float64\n",
      "earn_date          1410 non-null datetime64[ns]\n",
      "actual_dt_e        1410 non-null datetime64[ns]\n",
      "clean_text         1410 non-null object\n",
      "dtypes: datetime64[ns](4), float64(8), int32(5), object(5)\n",
      "memory usage: 225.8+ KB\n"
     ]
    }
   ],
   "source": [
    "final_sample = full_sample4.copy(deep=True)\n",
    "final_sample = final_sample.loc[final_sample['financial_tweet'] == 1]\n",
    "final_sample.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the machine learning and NLP analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((846, 1), (846,), (564, 1), (564,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = final_sample[['vol','ret','price','mcap','cashtag_tweet','fin_tweet','financial_tweet', \\\n",
    "                              'financial_url','numest','stdev','clean_text','ticker','actual_dt_e']]\n",
    "y = final_sample['eps_beat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .4, random_state = 321) \n",
    "\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "X_train_text = pd.DataFrame(X_train['clean_text']).reset_index(drop=True)\n",
    "X_test_text = pd.DataFrame(X_test['clean_text']).reset_index(drop=True)\n",
    "\n",
    "X_train_meta = X_train.drop(columns = 'clean_text').reset_index(drop=True)\n",
    "X_test_meta = X_test.drop(columns = 'clean_text').reset_index(drop=True)\n",
    "\n",
    "X_train_text.shape, y_train.shape, X_test_text.shape, y_test.shape, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a few new variables (based on the cleaned text - may want to consider doing this before preprocessing text too) to determine if tweet characteristics improve model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "X_train_meta['char_count'] = X_train_text['clean_text'].apply(len)\n",
    "X_train_meta['word_count'] = X_train_text['clean_text'].apply(lambda x: len(x.split()))\n",
    "X_train_meta['word_density'] = X_train_meta['char_count'] / X_train_meta['word_count']\n",
    "\n",
    "X_test_meta['char_count'] = X_test_text['clean_text'].apply(len)\n",
    "X_test_meta['word_count'] = X_test_text['clean_text'].apply(lambda x: len(x.split()))\n",
    "X_test_meta['word_density'] = X_test_meta['char_count'] / X_test_meta['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a basic count vectorizer with single words to begin with textual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0., max_df=1., ngram_range=(1,4))\n",
    "\n",
    "X_train_text_cv = pd.DataFrame(cv.fit_transform(X_train_text['clean_text']).toarray())\n",
    "\n",
    "X_test_text_cv = pd.DataFrame(cv.transform(X_test_text['clean_text']).toarray())\n",
    "\n",
    "\n",
    "X_train_full = pd.concat([X_train_text_cv, X_train_meta], axis=1)\n",
    "X_test_full = pd.concat([X_test_text_cv, X_test_meta], axis=1)\n",
    "\n",
    "X_train_full.drop(columns = ['mcap','cashtag_tweet','fin_tweet','financial_tweet','ret','vol','price','numest','stdev'], inplace=True)\n",
    "X_test_full.drop(columns = ['mcap','cashtag_tweet','fin_tweet','financial_tweet','ret','vol','price','numest','stdev'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores for all models based on CV:\n",
      "\n",
      "0.48818 (+/-0.03597) for {'alpha': 1}\n",
      "0.56974 (+/-0.02591) for {'alpha': 2}\n",
      "0.59102 (+/-0.04897) for {'alpha': 3}\n",
      "0.60757 (+/-0.05150) for {'alpha': 4}\n",
      "0.64184 (+/-0.05861) for {'alpha': 5}\n",
      "0.65366 (+/-0.05141) for {'alpha': 6}\n",
      "0.67139 (+/-0.04688) for {'alpha': 7}\n",
      "0.68558 (+/-0.04133) for {'alpha': 8}\n",
      "0.69031 (+/-0.02418) for {'alpha': 9}\n",
      "0.69031 (+/-0.03663) for {'alpha': 10}\n",
      "0.69504 (+/-0.02298) for {'alpha': 11}\n",
      "0.69976 (+/-0.02739) for {'alpha': 12}\n",
      "0.69504 (+/-0.02301) for {'alpha': 13}\n",
      "0.69267 (+/-0.03118) for {'alpha': 14}\n",
      "0.69267 (+/-0.02975) for {'alpha': 15}\n",
      "\n",
      "Best parameters set found on train: {'alpha': 12}\n",
      "\n",
      "Best model validation accuracy: 0.6997635933806147\n"
     ]
    }
   ],
   "source": [
    "import sklearn.naive_bayes\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "grid_params = {'alpha':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]}\n",
    "\n",
    "mnb = sklearn.naive_bayes.MultinomialNB()\n",
    "\n",
    "cv_mnb = GridSearchCV(mnb, grid_params, cv = 5)\n",
    "\n",
    "cv_mnb.fit(X_train_text_cv,y_train)\n",
    "\n",
    "print('Grid scores for all models based on CV:\\n')\n",
    "means = cv_mnb.cv_results_['mean_test_score']\n",
    "stds = cv_mnb.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, cv_mnb.cv_results_['params']):\n",
    "    print(\"%0.5f (+/-%0.05f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "print('\\nBest parameters set found on train:', cv_mnb.best_params_)\n",
    "print('\\nBest model validation accuracy:', cv_mnb.best_score_)\n",
    "\n",
    "best_model = cv_mnb.best_estimator_\n",
    "\n",
    "X_prob_train = pd.DataFrame(best_model.predict_proba(X_train_text_cv)[:,1], columns=['probability'])\n",
    "X_prob_test = pd.DataFrame(best_model.predict_proba(X_test_text_cv)[:,1], columns=['probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 846 entries, 0 to 845\n",
      "Data columns (total 15 columns):\n",
      "vol                846 non-null float64\n",
      "ret                846 non-null float64\n",
      "price              846 non-null float64\n",
      "mcap               846 non-null float64\n",
      "cashtag_tweet      846 non-null int32\n",
      "fin_tweet          846 non-null int32\n",
      "financial_tweet    846 non-null int32\n",
      "financial_url      846 non-null int32\n",
      "numest             846 non-null float64\n",
      "stdev              846 non-null float64\n",
      "ticker             846 non-null object\n",
      "actual_dt_e        846 non-null datetime64[ns]\n",
      "char_count         846 non-null int64\n",
      "word_count         846 non-null int64\n",
      "word_density       846 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(7), int32(4), int64(2), object(1)\n",
      "memory usage: 86.0+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train_meta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta2 = pd.concat([X_prob_train, X_train_meta,y_train], axis=1)\n",
    "X_model_2_train = X_train_meta2.groupby(['ticker','actual_dt_e'], as_index=False).agg({'probability':'mean','cashtag_tweet':'mean', \\\n",
    "                                                                                'financial_url':'mean', 'numest':'max', \\\n",
    "                                                                                'char_count':'mean', 'word_count':'mean', \\\n",
    "                                                                                'word_density':'mean','eps_beat':'max'})\n",
    "y_model_2_train = X_model_2_train['eps_beat']\n",
    "X_model_2_train = X_model_2_train.drop(columns=['eps_beat','actual_dt_e','ticker'])\n",
    "\n",
    "\n",
    "X_test_meta2 = pd.concat([X_prob_test, X_test_meta,y_test], axis=1)\n",
    "X_model_2_test = X_test_meta2.groupby(['ticker','actual_dt_e'], as_index=False).agg({'probability':'mean','cashtag_tweet':'mean', \\\n",
    "                                                                                'financial_url':'mean', 'numest':'max', \\\n",
    "                                                                                'char_count':'mean', 'word_count':'mean', \\\n",
    "                                                                                'word_density':'mean','eps_beat':'max'})\n",
    "y_model_2_test = X_model_2_test['eps_beat']\n",
    "X_model_2_test = X_model_2_test.drop(columns=['eps_beat','actual_dt_e','ticker'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 565 entries, 0 to 564\n",
      "Data columns (total 7 columns):\n",
      "probability      565 non-null float64\n",
      "cashtag_tweet    565 non-null float64\n",
      "financial_url    565 non-null float64\n",
      "numest           565 non-null float64\n",
      "char_count       565 non-null float64\n",
      "word_count       565 non-null float64\n",
      "word_density     565 non-null float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "X_model_2_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores for all models based on CV:\n",
      "\n",
      "0.66903 (+/-0.13178) for {'alpha': 1}\n",
      "0.66903 (+/-0.13178) for {'alpha': 2}\n",
      "0.66903 (+/-0.13178) for {'alpha': 3}\n",
      "0.67080 (+/-0.13498) for {'alpha': 4}\n",
      "0.67080 (+/-0.13498) for {'alpha': 5}\n",
      "0.67257 (+/-0.13197) for {'alpha': 6}\n",
      "0.67257 (+/-0.13197) for {'alpha': 7}\n",
      "0.66903 (+/-0.12987) for {'alpha': 8}\n",
      "0.66726 (+/-0.13320) for {'alpha': 9}\n",
      "0.66903 (+/-0.13691) for {'alpha': 10}\n",
      "0.66903 (+/-0.13691) for {'alpha': 11}\n",
      "0.66726 (+/-0.14053) for {'alpha': 12}\n",
      "0.66549 (+/-0.12783) for {'alpha': 13}\n",
      "0.66372 (+/-0.12364) for {'alpha': 14}\n",
      "0.66549 (+/-0.12832) for {'alpha': 15}\n",
      "\n",
      "Best parameters set found on train: {'alpha': 6}\n",
      "\n",
      "Best model validation accuracy: 0.672566371681416\n",
      "0.6307692307692307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.20      0.25       123\n",
      "         1.0       0.69      0.83      0.76       267\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       390\n",
      "   macro avg       0.52      0.51      0.50       390\n",
      "weighted avg       0.58      0.63      0.60       390\n",
      "\n",
      "[[ 24  99]\n",
      " [ 45 222]]\n"
     ]
    }
   ],
   "source": [
    "grid_params = {'alpha':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]}\n",
    "\n",
    "mnb = sklearn.naive_bayes.MultinomialNB()\n",
    "\n",
    "cv_mnb = GridSearchCV(mnb, grid_params, cv = 5)\n",
    "\n",
    "cv_mnb.fit(X_model_2_train, y_model_2_train)\n",
    "\n",
    "print('Grid scores for all models based on CV:\\n')\n",
    "means = cv_mnb.cv_results_['mean_test_score']\n",
    "stds = cv_mnb.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, cv_mnb.cv_results_['params']):\n",
    "    print(\"%0.5f (+/-%0.05f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "print('\\nBest parameters set found on train:', cv_mnb.best_params_)\n",
    "print('\\nBest model validation accuracy:', cv_mnb.best_score_)\n",
    "\n",
    "best_model = cv_mnb.best_estimator_\n",
    "\n",
    "prediction_mnb = best_model.predict(X_model_2_test)\n",
    "y_prob = best_model.predict_proba(X_model_2_test)\n",
    "\n",
    "print(best_model.score(X_model_2_test, y_model_2_test))\n",
    "print(classification_report(y_model_2_test, prediction_mnb))\n",
    "print(confusion_matrix(y_model_2_test, prediction_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores for all models based on CV:\n",
      "\n",
      "0.32743 (+/-0.00000) for {'C': 0.0001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.0001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.53805 (+/-0.13498) for {'C': 0.0001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.53805 (+/-0.13498) for {'C': 0.0001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.32743 (+/-0.00000) for {'C': 0.0001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.0001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.0001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.0001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.32743 (+/-0.00000) for {'C': 0.001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.60354 (+/-0.27611) for {'C': 0.001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.55929 (+/-0.16121) for {'C': 0.001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.55752 (+/-0.15631) for {'C': 0.001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.56460 (+/-0.18202) for {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.52389 (+/-0.11708) for {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.71504 (+/-0.22287) for {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.71681 (+/-0.22049) for {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.01, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.01, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.01, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.01, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89735 (+/-0.07476) for {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89735 (+/-0.07476) for {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89381 (+/-0.04879) for {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89735 (+/-0.05664) for {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.87611 (+/-0.06622) for {'C': 0.1, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.87788 (+/-0.06469) for {'C': 0.1, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.84425 (+/-0.06192) for {'C': 0.1, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.84248 (+/-0.06469) for {'C': 0.1, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.90088 (+/-0.05859) for {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.90265 (+/-0.05484) for {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89912 (+/-0.06679) for {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89558 (+/-0.05529) for {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89558 (+/-0.07202) for {'C': 0.5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89204 (+/-0.07026) for {'C': 0.5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.88496 (+/-0.06430) for {'C': 0.5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.88142 (+/-0.06772) for {'C': 0.5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89558 (+/-0.05529) for {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.90265 (+/-0.05006) for {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89735 (+/-0.07133) for {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89735 (+/-0.06090) for {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89735 (+/-0.06772) for {'C': 0.75, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89204 (+/-0.07026) for {'C': 0.75, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89204 (+/-0.06565) for {'C': 0.75, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.88496 (+/-0.06430) for {'C': 0.75, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89558 (+/-0.05529) for {'C': 0.99, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89912 (+/-0.05664) for {'C': 0.99, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89735 (+/-0.06090) for {'C': 0.99, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89735 (+/-0.06090) for {'C': 0.99, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89912 (+/-0.07220) for {'C': 0.99, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89381 (+/-0.07425) for {'C': 0.99, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89381 (+/-0.06900) for {'C': 0.99, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89204 (+/-0.06565) for {'C': 0.99, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89204 (+/-0.06273) for {'C': 2, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89735 (+/-0.05081) for {'C': 2, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89558 (+/-0.05529) for {'C': 2, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89381 (+/-0.06028) for {'C': 2, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.90088 (+/-0.05859) for {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89381 (+/-0.07425) for {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89558 (+/-0.07026) for {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89204 (+/-0.06565) for {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.88673 (+/-0.04930) for {'C': 5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89558 (+/-0.05529) for {'C': 5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89912 (+/-0.05664) for {'C': 5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89558 (+/-0.05529) for {'C': 5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.90442 (+/-0.05056) for {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89558 (+/-0.07026) for {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.90088 (+/-0.06172) for {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89381 (+/-0.06900) for {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "\n",
      "Best parameters set found on train: {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n",
      "Best model validation accuracy: 0.904424778761062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1acb71c8320>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "grid_params = {'penalty':['l1','l2'], 'C':[0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 0.99, 2, 5], 'solver':['liblinear','saga'], \\\n",
    "              'max_iter':[10000], 'class_weight':['balanced',None]}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "cv_lr = GridSearchCV(lr, grid_params, cv = 5)\n",
    "\n",
    "cv_lr.fit(X_model_2_train,y_model_2_train)\n",
    "\n",
    "print('Grid scores for all models based on CV:\\n')\n",
    "means = cv_lr.cv_results_['mean_test_score']\n",
    "stds = cv_lr.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, cv_lr.cv_results_['params']):\n",
    "    print(\"%0.5f (+/-%0.05f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "print('\\nBest parameters set found on train:', cv_lr.best_params_)\n",
    "print('\\nBest model validation accuracy:', cv_lr.best_score_)\n",
    "\n",
    "best_model = cv_lr.best_estimator_\n",
    "\n",
    "y_lr = best_model.predict_proba(X_model_2_train)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_model_2_train, y_lr[:,1])\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10, label='threshold zero', fillstyle='none', c='k', mew=2)\n",
    "\n",
    "plt.plot(fpr, tpr, label = 'p r curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0, 1.9928707461025668)\n",
      "(0.0, 0.002631578947368421, 0.9928707461025669)\n",
      "(0.0, 0.09210526315789473, 0.9733023607828115)\n",
      "(0.005405405405405406, 0.09210526315789473, 0.9720728624779366)\n",
      "(0.005405405405405406, 0.10526315789473684, 0.9701443780673088)\n",
      "(0.005405405405405406, 0.11052631578947368, 0.969994403000775)\n",
      "(0.005405405405405406, 0.12368421052631579, 0.9688007915963648)\n",
      "(0.016216216216216217, 0.12368421052631579, 0.9682837547053177)\n",
      "(0.016216216216216217, 0.1868421052631579, 0.9602326341125726)\n",
      "(0.021621621621621623, 0.1868421052631579, 0.9600179989621184)\n",
      "(0.021621621621621623, 0.25263157894736843, 0.9526611906997415)\n",
      "(0.02702702702702703, 0.25263157894736843, 0.9524977024204531)\n",
      "(0.02702702702702703, 0.2894736842105263, 0.9490135375344728)\n",
      "(0.032432432432432434, 0.2894736842105263, 0.9476815922074106)\n",
      "(0.032432432432432434, 0.35789473684210527, 0.9404247117096788)\n",
      "(0.03783783783783784, 0.35789473684210527, 0.9400952740589554)\n",
      "(0.03783783783783784, 0.3815789473684211, 0.9369205012132925)\n",
      "(0.043243243243243246, 0.3815789473684211, 0.9357658927241165)\n",
      "(0.043243243243243246, 0.38421052631578945, 0.935755057143525)\n",
      "(0.043243243243243246, 0.39210526315789473, 0.9352440293980947)\n",
      "(0.043243243243243246, 0.4236842105263158, 0.9280437296856907)\n",
      "(0.04864864864864865, 0.4236842105263158, 0.9280105707306208)\n",
      "(0.04864864864864865, 0.45263157894736844, 0.9247264690781163)\n",
      "(0.05405405405405406, 0.45263157894736844, 0.9247249521777169)\n",
      "(0.05405405405405406, 0.46578947368421053, 0.9212607335246203)\n",
      "(0.05945945945945946, 0.46578947368421053, 0.9198772245549534)\n",
      "(0.05945945945945946, 0.4710526315789474, 0.9187327393875616)\n",
      "(0.05945945945945946, 0.4763157894736842, 0.9183607280075052)\n",
      "(0.05945945945945946, 0.48157894736842105, 0.9181862858184935)\n",
      "(0.06486486486486487, 0.48157894736842105, 0.918168285668886)\n",
      "(0.06486486486486487, 0.5631578947368421, 0.9077589541395912)\n",
      "(0.07027027027027027, 0.5631578947368421, 0.906462430015282)\n",
      "(0.07027027027027027, 0.6, 0.9008737748234068)\n",
      "(0.07567567567567568, 0.6, 0.900359803653554)\n",
      "(0.07567567567567568, 0.6026315789473684, 0.8997467395312646)\n",
      "(0.08108108108108109, 0.6026315789473684, 0.899625193723824)\n",
      "(0.08108108108108109, 0.6421052631578947, 0.8928312503828403)\n",
      "(0.08648648648648649, 0.6421052631578947, 0.8920305808011333)\n",
      "(0.08648648648648649, 0.6894736842105263, 0.8813789280088025)\n",
      "(0.0918918918918919, 0.6894736842105263, 0.8812644509242625)\n",
      "(0.0918918918918919, 0.7131578947368421, 0.8769041571779106)\n",
      "(0.0972972972972973, 0.7131578947368421, 0.8768528501079053)\n",
      "(0.0972972972972973, 0.7157894736842105, 0.8759946594808621)\n",
      "(0.10270270270270271, 0.7157894736842105, 0.8738644275445305)\n",
      "(0.10270270270270271, 0.7447368421052631, 0.8625697813552764)\n",
      "(0.10810810810810811, 0.7447368421052631, 0.8624218710310977)\n",
      "(0.10810810810810811, 0.7605263157894737, 0.8576045254287651)\n",
      "(0.11351351351351352, 0.7605263157894737, 0.8555065794403982)\n",
      "(0.11351351351351352, 0.7763157894736842, 0.8490206042150282)\n",
      "(0.11891891891891893, 0.7763157894736842, 0.8470679222914138)\n",
      "(0.11891891891891893, 0.7894736842105263, 0.8408150117874373)\n",
      "(0.12432432432432433, 0.7894736842105263, 0.8399823921402851)\n",
      "(0.12432432432432433, 0.8131578947368421, 0.8259580538532566)\n",
      "(0.12972972972972974, 0.8131578947368421, 0.825834476638034)\n",
      "(0.12972972972972974, 0.8157894736842105, 0.825742489604373)\n",
      "(0.13513513513513514, 0.8157894736842105, 0.8254099056576623)\n",
      "(0.13513513513513514, 0.8421052631578947, 0.8044307654940512)\n",
      "(0.14054054054054055, 0.8421052631578947, 0.8043589925597467)\n",
      "(0.14054054054054055, 0.85, 0.8002602947297747)\n",
      "(0.14594594594594595, 0.85, 0.7996027984950909)\n",
      "(0.14594594594594595, 0.8578947368421053, 0.7952258564060402)\n",
      "(0.15135135135135136, 0.8578947368421053, 0.794195517015683)\n",
      "(0.15135135135135136, 0.868421052631579, 0.7847065693701325)\n",
      "(0.15675675675675677, 0.868421052631579, 0.7844226862147644)\n",
      "(0.15675675675675677, 0.8736842105263158, 0.7834324888406985)\n",
      "(0.16216216216216217, 0.8736842105263158, 0.7833811614118302)\n",
      "(0.16216216216216217, 0.881578947368421, 0.7790743296545415)\n",
      "(0.16756756756756758, 0.881578947368421, 0.7789905468973758)\n",
      "(0.16756756756756758, 0.9157894736842105, 0.7532599075551142)\n",
      "(0.17297297297297298, 0.9157894736842105, 0.7528405514130072)\n",
      "(0.17297297297297298, 0.9263157894736842, 0.7401944275964337)\n",
      "(0.1783783783783784, 0.9263157894736842, 0.7368907459413986)\n",
      "(0.1783783783783784, 0.9342105263157895, 0.7272930133956094)\n",
      "(0.1837837837837838, 0.9342105263157895, 0.7246577415467432)\n",
      "(0.1837837837837838, 0.9394736842105263, 0.7090691682599733)\n",
      "(0.1891891891891892, 0.9394736842105263, 0.7055342237925535)\n",
      "(0.1891891891891892, 0.9473684210526315, 0.6989229148345596)\n",
      "(0.2, 0.9473684210526315, 0.6891792434391781)\n",
      "(0.2, 0.95, 0.6866763298063656)\n",
      "(0.20540540540540542, 0.95, 0.6857540741316148)\n",
      "(0.20540540540540542, 0.9526315789473684, 0.6853430531711913)\n",
      "(0.21081081081081082, 0.9526315789473684, 0.6766762567190776)\n",
      "(0.21081081081081082, 0.9631578947368421, 0.6543936154472518)\n",
      "(0.22162162162162163, 0.9631578947368421, 0.6535498466679502)\n",
      "(0.22162162162162163, 0.9710526315789474, 0.6369526092020448)\n",
      "(0.22702702702702704, 0.9710526315789474, 0.6350663329308742)\n",
      "(0.22702702702702704, 0.9763157894736842, 0.6036503583456799)\n",
      "(0.23243243243243245, 0.9763157894736842, 0.5977578698107957)\n",
      "(0.23243243243243245, 0.9921052631578947, 0.5610742561308879)\n",
      "(0.23783783783783785, 0.9921052631578947, 0.5536771277176451)\n",
      "(0.23783783783783785, 0.9947368421052631, 0.5513208136773616)\n",
      "(0.2864864864864865, 0.9947368421052631, 0.43303764048477067)\n",
      "(0.2864864864864865, 1.0, 0.401782140863905)\n",
      "(1.0, 1.0, 2.2168616638740265e-07)\n"
     ]
    }
   ],
   "source": [
    "for row in zip(fpr, tpr, thresholds):\n",
    "    print(row)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144  41]\n",
      " [ 11 369]]\n"
     ]
    }
   ],
   "source": [
    "y_probs = pd.DataFrame(y_lr[:,1]).copy(deep=True)\n",
    "y_probs['new_pred'] = (y_probs >= 0.6369526092020448).astype(int)\n",
    "y_probs_pred = y_probs['new_pred']\n",
    "\n",
    "print(confusion_matrix(y_model_2_train, y_probs_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7025641025641025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.31      0.40       123\n",
      "         1.0       0.74      0.88      0.80       267\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       390\n",
      "   macro avg       0.64      0.60      0.60       390\n",
      "weighted avg       0.68      0.70      0.67       390\n",
      "\n",
      "[[ 38  85]\n",
      " [ 31 236]]\n",
      "   probability  cashtag_tweet  financial_url    numest  char_count  \\\n",
      "0    16.983421       -0.63176      -1.642211  0.017075    0.058494   \n",
      "\n",
      "   word_count  word_density  \n",
      "0   -0.510048      -0.15546  \n"
     ]
    }
   ],
   "source": [
    "prediction_lr = best_model.predict(X_model_2_test)\n",
    "\n",
    "print(best_model.score(X_model_2_test, y_model_2_test))\n",
    "print(classification_report(y_model_2_test, prediction_lr))\n",
    "print(confusion_matrix(y_model_2_test, prediction_lr))\n",
    "print(pd.DataFrame(best_model.coef_.tolist(),columns=X_model_2_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.37      0.42       123\n",
      "         1.0       0.74      0.81      0.77       267\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       390\n",
      "   macro avg       0.61      0.59      0.59       390\n",
      "weighted avg       0.65      0.67      0.66       390\n",
      "\n",
      "[[ 46  77]\n",
      " [ 51 216]]\n"
     ]
    }
   ],
   "source": [
    "y_probs_test = best_model.predict_proba(X_model_2_test)\n",
    "y_probs_test = pd.DataFrame(y_probs_test[:,1]).copy(deep=True)\n",
    "\n",
    "y_probs_test['new_pred'] = (y_probs_test >= 0.6369526092020448).astype(int)\n",
    "y_probs_pred_test = y_probs_test['new_pred']\n",
    "\n",
    "print(classification_report(y_model_2_test, y_probs_pred_test))\n",
    "print(confusion_matrix(y_model_2_test, y_probs_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results from the logistic regression to those of a Random Forest.\n",
    "\n",
    "Must still maintain the first step model where we obtain probabilities of earnings beats from Twitter content. But in step 2 of the model, we now use the RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores for all models based on CV:\n",
      "\n",
      "0.88319 (+/-0.04802) for {'max_depth': 5, 'max_features': 2, 'n_estimators': 10}\n",
      "0.88673 (+/-0.05298) for {'max_depth': 5, 'max_features': 2, 'n_estimators': 50}\n",
      "0.89027 (+/-0.05322) for {'max_depth': 5, 'max_features': 2, 'n_estimators': 100}\n",
      "0.88850 (+/-0.04828) for {'max_depth': 5, 'max_features': 3, 'n_estimators': 10}\n",
      "0.88850 (+/-0.06090) for {'max_depth': 5, 'max_features': 3, 'n_estimators': 50}\n",
      "0.88850 (+/-0.05438) for {'max_depth': 5, 'max_features': 3, 'n_estimators': 100}\n",
      "0.88850 (+/-0.04561) for {'max_depth': 5, 'max_features': 4, 'n_estimators': 10}\n",
      "0.89558 (+/-0.03432) for {'max_depth': 5, 'max_features': 4, 'n_estimators': 50}\n",
      "0.89735 (+/-0.03973) for {'max_depth': 5, 'max_features': 4, 'n_estimators': 100}\n",
      "0.88319 (+/-0.02064) for {'max_depth': 10, 'max_features': 2, 'n_estimators': 10}\n",
      "0.88850 (+/-0.01805) for {'max_depth': 10, 'max_features': 2, 'n_estimators': 50}\n",
      "0.89381 (+/-0.02503) for {'max_depth': 10, 'max_features': 2, 'n_estimators': 100}\n",
      "0.87434 (+/-0.03779) for {'max_depth': 10, 'max_features': 3, 'n_estimators': 10}\n",
      "0.89027 (+/-0.01805) for {'max_depth': 10, 'max_features': 3, 'n_estimators': 50}\n",
      "0.89381 (+/-0.04036) for {'max_depth': 10, 'max_features': 3, 'n_estimators': 100}\n",
      "0.88496 (+/-0.04036) for {'max_depth': 10, 'max_features': 4, 'n_estimators': 10}\n",
      "0.89204 (+/-0.03432) for {'max_depth': 10, 'max_features': 4, 'n_estimators': 50}\n",
      "0.89381 (+/-0.01583) for {'max_depth': 10, 'max_features': 4, 'n_estimators': 100}\n",
      "0.87257 (+/-0.02876) for {'max_depth': 25, 'max_features': 2, 'n_estimators': 10}\n",
      "0.88496 (+/-0.01939) for {'max_depth': 25, 'max_features': 2, 'n_estimators': 50}\n",
      "0.89381 (+/-0.02503) for {'max_depth': 25, 'max_features': 2, 'n_estimators': 100}\n",
      "0.87965 (+/-0.05664) for {'max_depth': 25, 'max_features': 3, 'n_estimators': 10}\n",
      "0.89204 (+/-0.01324) for {'max_depth': 25, 'max_features': 3, 'n_estimators': 50}\n",
      "0.89204 (+/-0.01734) for {'max_depth': 25, 'max_features': 3, 'n_estimators': 100}\n",
      "0.88673 (+/-0.02064) for {'max_depth': 25, 'max_features': 4, 'n_estimators': 10}\n",
      "0.89735 (+/-0.03973) for {'max_depth': 25, 'max_features': 4, 'n_estimators': 50}\n",
      "0.89735 (+/-0.01805) for {'max_depth': 25, 'max_features': 4, 'n_estimators': 100}\n",
      "0.87257 (+/-0.02876) for {'max_depth': 50, 'max_features': 2, 'n_estimators': 10}\n",
      "0.88496 (+/-0.01939) for {'max_depth': 50, 'max_features': 2, 'n_estimators': 50}\n",
      "0.89381 (+/-0.02503) for {'max_depth': 50, 'max_features': 2, 'n_estimators': 100}\n",
      "0.87965 (+/-0.05664) for {'max_depth': 50, 'max_features': 3, 'n_estimators': 10}\n",
      "0.89204 (+/-0.01324) for {'max_depth': 50, 'max_features': 3, 'n_estimators': 50}\n",
      "0.89204 (+/-0.01734) for {'max_depth': 50, 'max_features': 3, 'n_estimators': 100}\n",
      "0.88673 (+/-0.02064) for {'max_depth': 50, 'max_features': 4, 'n_estimators': 10}\n",
      "0.89735 (+/-0.03973) for {'max_depth': 50, 'max_features': 4, 'n_estimators': 50}\n",
      "0.89735 (+/-0.01805) for {'max_depth': 50, 'max_features': 4, 'n_estimators': 100}\n",
      "0.87257 (+/-0.02876) for {'max_depth': 100, 'max_features': 2, 'n_estimators': 10}\n",
      "0.88496 (+/-0.01939) for {'max_depth': 100, 'max_features': 2, 'n_estimators': 50}\n",
      "0.89381 (+/-0.02503) for {'max_depth': 100, 'max_features': 2, 'n_estimators': 100}\n",
      "0.87965 (+/-0.05664) for {'max_depth': 100, 'max_features': 3, 'n_estimators': 10}\n",
      "0.89204 (+/-0.01324) for {'max_depth': 100, 'max_features': 3, 'n_estimators': 50}\n",
      "0.89204 (+/-0.01734) for {'max_depth': 100, 'max_features': 3, 'n_estimators': 100}\n",
      "0.88673 (+/-0.02064) for {'max_depth': 100, 'max_features': 4, 'n_estimators': 10}\n",
      "0.89735 (+/-0.03973) for {'max_depth': 100, 'max_features': 4, 'n_estimators': 50}\n",
      "0.89735 (+/-0.01805) for {'max_depth': 100, 'max_features': 4, 'n_estimators': 100}\n",
      "\n",
      "Best parameters set found on train: {'max_depth': 5, 'max_features': 4, 'n_estimators': 100}\n",
      "\n",
      "Best model validation accuracy: 0.8973451327433628\n",
      "(0.0, 0.0, 1.9694776271400332)\n",
      "(0.0, 0.002631578947368421, 0.9694776271400333)\n",
      "(0.0, 0.03684210526315789, 0.9627849670409618)\n",
      "(0.0, 0.042105263157894736, 0.9625835321720173)\n",
      "(0.0, 0.08157894736842106, 0.9601966911629859)\n",
      "(0.0, 0.08947368421052632, 0.9601368816495495)\n",
      "(0.0, 0.26842105263157895, 0.9533247104860126)\n",
      "(0.0, 0.2736842105263158, 0.9532770000221441)\n",
      "(0.0, 0.33157894736842103, 0.9503415021158409)\n",
      "(0.0, 0.3368421052631579, 0.9500068316600205)\n",
      "(0.0, 0.5368421052631579, 0.9366643321323488)\n",
      "(0.005405405405405406, 0.5368421052631579, 0.9363975952648644)\n",
      "(0.005405405405405406, 0.6052631578947368, 0.9273743805926772)\n",
      "(0.010810810810810811, 0.6078947368421053, 0.9267219120117376)\n",
      "(0.010810810810810811, 0.6105263157894737, 0.9263566598840282)\n",
      "(0.010810810810810811, 0.6157894736842106, 0.9263227678038554)\n",
      "(0.010810810810810811, 0.6236842105263158, 0.9253722050309569)\n",
      "(0.016216216216216217, 0.6236842105263158, 0.9243405373788083)\n",
      "(0.016216216216216217, 0.6631578947368421, 0.9141914575487795)\n",
      "(0.021621621621621623, 0.6631578947368421, 0.9106743320893607)\n",
      "(0.021621621621621623, 0.6973684210526315, 0.8995993445824864)\n",
      "(0.02702702702702703, 0.6973684210526315, 0.8968138636423559)\n",
      "(0.02702702702702703, 0.7447368421052631, 0.8862765905511619)\n",
      "(0.032432432432432434, 0.7447368421052631, 0.8849357823296464)\n",
      "(0.032432432432432434, 0.781578947368421, 0.8719740343209046)\n",
      "(0.03783783783783784, 0.781578947368421, 0.8717741857629986)\n",
      "(0.03783783783783784, 0.8263157894736842, 0.8492176213229206)\n",
      "(0.043243243243243246, 0.8263157894736842, 0.8474680907003947)\n",
      "(0.043243243243243246, 0.8710526315789474, 0.8290102680441014)\n",
      "(0.05405405405405406, 0.8710526315789474, 0.8277608492799121)\n",
      "(0.05405405405405406, 0.881578947368421, 0.8199463097623783)\n",
      "(0.05945945945945946, 0.881578947368421, 0.8198998035124592)\n",
      "(0.05945945945945946, 0.9, 0.8032105620665965)\n",
      "(0.07027027027027027, 0.9, 0.8026453119254968)\n",
      "(0.07027027027027027, 0.9210526315789473, 0.7899509225242132)\n",
      "(0.07567567567567568, 0.9210526315789473, 0.7872194598909522)\n",
      "(0.07567567567567568, 0.9394736842105263, 0.7688236476616602)\n",
      "(0.08108108108108109, 0.9394736842105263, 0.7668576207582868)\n",
      "(0.08108108108108109, 0.95, 0.7607932132077372)\n",
      "(0.08648648648648649, 0.95, 0.7532666726363092)\n",
      "(0.08648648648648649, 0.9526315789473684, 0.7510727718292557)\n",
      "(0.0918918918918919, 0.9526315789473684, 0.7493155530329416)\n",
      "(0.0918918918918919, 0.9631578947368421, 0.7450822529912168)\n",
      "(0.10810810810810811, 0.9631578947368421, 0.7326143187937539)\n",
      "(0.10810810810810811, 0.968421052631579, 0.7312855594984877)\n",
      "(0.11351351351351352, 0.968421052631579, 0.7309766566672126)\n",
      "(0.11351351351351352, 0.9789473684210527, 0.718657017174535)\n",
      "(0.11891891891891893, 0.9789473684210527, 0.704417862798646)\n",
      "(0.11891891891891893, 0.9894736842105263, 0.6802740932182806)\n",
      "(0.12972972972972974, 0.9894736842105263, 0.6692785741352424)\n",
      "(0.12972972972972974, 0.9921052631578947, 0.6688590955485623)\n",
      "(0.13513513513513514, 0.9921052631578947, 0.6665369046375444)\n",
      "(0.13513513513513514, 0.9947368421052631, 0.6456830560970164)\n",
      "(0.17297297297297298, 0.9947368421052631, 0.6134546610721195)\n",
      "(0.17297297297297298, 0.9973684210526316, 0.6128076462020615)\n",
      "(0.1891891891891892, 0.9973684210526316, 0.5978102204665002)\n",
      "(0.1891891891891892, 1.0, 0.5916950686736818)\n",
      "(0.4702702702702703, 1.0, 0.013189282627484875)\n",
      "(0.5027027027027027, 1.0, 0.012630420483908856)\n",
      "(0.5135135135135135, 1.0, 0.01180864128844545)\n",
      "(0.5243243243243243, 1.0, 0.011657210048900668)\n",
      "(0.5405405405405406, 1.0, 0.01089854027834444)\n",
      "(0.5513513513513514, 1.0, 0.010419309372797746)\n",
      "(0.5621621621621622, 1.0, 0.010112359550561799)\n",
      "(0.572972972972973, 1.0, 0.01)\n",
      "(0.6, 1.0, 0.00823860761841178)\n",
      "(0.6162162162162163, 1.0, 0.008112359550561799)\n",
      "(0.6270270270270271, 1.0, 0.007630420483908855)\n",
      "(0.6378378378378379, 1.0, 0.007612359550561798)\n",
      "(0.6432432432432432, 1.0, 0.007327390180878552)\n",
      "(0.654054054054054, 1.0, 0.00726891064871481)\n",
      "(0.6594594594594595, 1.0, 0.006607068545270794)\n",
      "(0.6702702702702703, 1.0, 0.006519309372797745)\n",
      "(0.6864864864864865, 1.0, 0.006216279069767442)\n",
      "(0.6918918918918919, 1.0, 0.005687575818396873)\n",
      "(0.7027027027027027, 1.0, 0.0049905433822340015)\n",
      "(0.7189189189189189, 1.0, 0.004878183831672204)\n",
      "(0.7243243243243244, 1.0, 0.004755216693418941)\n",
      "(0.7837837837837838, 1.0, 0.004576464707285761)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7891891891891892, 1.0, 0.004464105156723964)\n",
      "(0.8, 1.0, 0.004112359550561798)\n",
      "(0.8108108108108109, 1.0, 0.0029193093727977446)\n",
      "(0.8378378378378378, 1.0, 0.0027286386203292396)\n",
      "(0.8432432432432433, 1.0, 0.0026162790697674423)\n",
      "(0.8540540540540541, 1.0, 0.002612359550561798)\n",
      "(0.8594594594594595, 1.0, 0.0014141414141414141)\n",
      "(0.8702702702702703, 1.0, 0.0004193093727977449)\n",
      "(0.8756756756756757, 1.0, 0.00030303030303030303)\n",
      "(0.9351351351351351, 1.0, 0.0002286386203292396)\n",
      "(0.9621621621621622, 1.0, 0.00011627906976744185)\n",
      "(1.0, 1.0, 0.00011235955056179774)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid_parms = {'n_estimators':[10, 50,100],'max_features':[2,3,4],'max_depth':[5,10,25,50,100]} \n",
    "\n",
    "RFC = RandomForestClassifier(random_state=123)\n",
    "cv = GridSearchCV(RFC, grid_parms, cv = 5)\n",
    "cv.fit(X_model_2_train,y_model_2_train)\n",
    "\n",
    "print('Grid scores for all models based on CV:\\n')\n",
    "means = cv.cv_results_['mean_test_score']\n",
    "stds = cv.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, cv.cv_results_['params']):\n",
    "    print(\"%0.5f (+/-%0.05f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "print('\\nBest parameters set found on train:', cv.best_params_)\n",
    "print('\\nBest model validation accuracy:', cv.best_score_)\n",
    "\n",
    "best_model = cv.best_estimator_\n",
    "\n",
    "y_rf = best_model.predict_proba(X_model_2_train)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_model_2_train, y_rf[:,1])\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10, label='threshold zero', fillstyle='none', c='k', mew=2)\n",
    "\n",
    "plt.plot(fpr, tpr, label = 'p r curve')\n",
    "\n",
    "for row in zip(fpr, tpr, thresholds):\n",
    "    print(row)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6743589743589744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.30      0.37       123\n",
      "         1.0       0.72      0.85      0.78       267\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       390\n",
      "   macro avg       0.60      0.57      0.57       390\n",
      "weighted avg       0.65      0.67      0.65       390\n",
      "\n",
      "[[ 37  86]\n",
      " [ 41 226]]\n"
     ]
    }
   ],
   "source": [
    "prediction_rf = best_model.predict(X_model_2_test)\n",
    "\n",
    "print(best_model.score(X_model_2_test, y_model_2_test))\n",
    "print(classification_report(y_model_2_test, prediction_rf))\n",
    "print(confusion_matrix(y_model_2_test, prediction_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.41      0.42       123\n",
      "         1.0       0.73      0.75      0.74       267\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       390\n",
      "   macro avg       0.58      0.58      0.58       390\n",
      "weighted avg       0.64      0.64      0.64       390\n",
      "\n",
      "[[ 50  73]\n",
      " [ 66 201]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>cashtag_tweet</th>\n",
       "      <th>financial_url</th>\n",
       "      <th>numest</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.837863</td>\n",
       "      <td>0.010721</td>\n",
       "      <td>0.00425</td>\n",
       "      <td>0.028635</td>\n",
       "      <td>0.035222</td>\n",
       "      <td>0.037751</td>\n",
       "      <td>0.045559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   probability  cashtag_tweet  financial_url    numest  char_count  \\\n",
       "0     0.837863       0.010721        0.00425  0.028635    0.035222   \n",
       "\n",
       "   word_count  word_density  \n",
       "0    0.037751      0.045559  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs_test = best_model.predict_proba(X_model_2_test)\n",
    "y_probs_test = pd.DataFrame(y_probs_test[:,1]).copy(deep=True)\n",
    "\n",
    "y_probs_test['new_pred'] = (y_probs_test >= 0.6802740932182806).astype(int)\n",
    "y_probs_pred_test = y_probs_test['new_pred']\n",
    "\n",
    "print(classification_report(y_model_2_test, y_probs_pred_test))\n",
    "print(confusion_matrix(y_model_2_test, y_probs_pred_test))\n",
    "\n",
    "imp_feat = pd.DataFrame(best_model.feature_importances_).transpose()\n",
    "imp_feat.columns = X_model_2_test.columns\n",
    "imp_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consider Standardizing non dummy indicator variables (probability, numest, char_count, word_count, word_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_dum = X_model_2_train[['cashtag_tweet','financial_url']]\n",
    "X_train_s = X_model_2_train.drop(columns=['cashtag_tweet','financial_url'])\n",
    "X_train_s = pd.DataFrame(scaler.fit_transform(X_train_s), columns=['probability','numest','char_count','word_count','word_density'])\n",
    "X_train_sf = pd.concat([X_train_dum.reset_index(drop=True), X_train_s.reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_test_dum = X_model_2_test[['cashtag_tweet','financial_url']]\n",
    "X_test_s = X_model_2_test.drop(columns=['cashtag_tweet','financial_url'])\n",
    "X_test_s = pd.DataFrame(scaler.transform(X_test_s), columns=['probability','numest','char_count','word_count','word_density'])\n",
    "X_test_sf = pd.concat([X_test_dum.reset_index(drop=True), X_test_s.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores for all models based on CV:\n",
      "\n",
      "0.89027 (+/-0.04696) for {'max_depth': 5, 'max_features': 2, 'n_estimators': 10}\n",
      "0.88496 (+/-0.05817) for {'max_depth': 5, 'max_features': 2, 'n_estimators': 50}\n",
      "0.88850 (+/-0.04828) for {'max_depth': 5, 'max_features': 2, 'n_estimators': 100}\n",
      "0.90265 (+/-0.03713) for {'max_depth': 5, 'max_features': 3, 'n_estimators': 10}\n",
      "0.89381 (+/-0.02962) for {'max_depth': 5, 'max_features': 3, 'n_estimators': 50}\n",
      "0.89558 (+/-0.04098) for {'max_depth': 5, 'max_features': 3, 'n_estimators': 100}\n",
      "0.90265 (+/-0.04036) for {'max_depth': 5, 'max_features': 4, 'n_estimators': 10}\n",
      "0.89735 (+/-0.04277) for {'max_depth': 5, 'max_features': 4, 'n_estimators': 50}\n",
      "0.89558 (+/-0.03432) for {'max_depth': 5, 'max_features': 4, 'n_estimators': 100}\n",
      "0.87257 (+/-0.02876) for {'max_depth': 10, 'max_features': 2, 'n_estimators': 10}\n",
      "0.89381 (+/-0.02962) for {'max_depth': 10, 'max_features': 2, 'n_estimators': 50}\n",
      "0.89204 (+/-0.02601) for {'max_depth': 10, 'max_features': 2, 'n_estimators': 100}\n",
      "0.89558 (+/-0.03432) for {'max_depth': 10, 'max_features': 3, 'n_estimators': 10}\n",
      "0.89912 (+/-0.01416) for {'max_depth': 10, 'max_features': 3, 'n_estimators': 50}\n",
      "0.90265 (+/-0.01583) for {'max_depth': 10, 'max_features': 3, 'n_estimators': 100}\n",
      "0.90088 (+/-0.03779) for {'max_depth': 10, 'max_features': 4, 'n_estimators': 10}\n",
      "0.89558 (+/-0.01734) for {'max_depth': 10, 'max_features': 4, 'n_estimators': 50}\n",
      "0.89735 (+/-0.01416) for {'max_depth': 10, 'max_features': 4, 'n_estimators': 100}\n",
      "0.87434 (+/-0.02832) for {'max_depth': 25, 'max_features': 2, 'n_estimators': 10}\n",
      "0.88850 (+/-0.03644) for {'max_depth': 25, 'max_features': 2, 'n_estimators': 50}\n",
      "0.88850 (+/-0.02649) for {'max_depth': 25, 'max_features': 2, 'n_estimators': 100}\n",
      "0.88850 (+/-0.03086) for {'max_depth': 25, 'max_features': 3, 'n_estimators': 10}\n",
      "0.89735 (+/-0.01416) for {'max_depth': 25, 'max_features': 3, 'n_estimators': 50}\n",
      "0.89735 (+/-0.01416) for {'max_depth': 25, 'max_features': 3, 'n_estimators': 100}\n",
      "0.89204 (+/-0.04248) for {'max_depth': 25, 'max_features': 4, 'n_estimators': 10}\n",
      "0.89027 (+/-0.02401) for {'max_depth': 25, 'max_features': 4, 'n_estimators': 50}\n",
      "0.89735 (+/-0.02401) for {'max_depth': 25, 'max_features': 4, 'n_estimators': 100}\n",
      "0.87434 (+/-0.02832) for {'max_depth': 50, 'max_features': 2, 'n_estimators': 10}\n",
      "0.88850 (+/-0.03644) for {'max_depth': 50, 'max_features': 2, 'n_estimators': 50}\n",
      "0.88850 (+/-0.02649) for {'max_depth': 50, 'max_features': 2, 'n_estimators': 100}\n",
      "0.88850 (+/-0.03086) for {'max_depth': 50, 'max_features': 3, 'n_estimators': 10}\n",
      "0.89735 (+/-0.01416) for {'max_depth': 50, 'max_features': 3, 'n_estimators': 50}\n",
      "0.89735 (+/-0.01416) for {'max_depth': 50, 'max_features': 3, 'n_estimators': 100}\n",
      "0.89204 (+/-0.04248) for {'max_depth': 50, 'max_features': 4, 'n_estimators': 10}\n",
      "0.89027 (+/-0.02401) for {'max_depth': 50, 'max_features': 4, 'n_estimators': 50}\n",
      "0.89735 (+/-0.02401) for {'max_depth': 50, 'max_features': 4, 'n_estimators': 100}\n",
      "0.87434 (+/-0.02832) for {'max_depth': 100, 'max_features': 2, 'n_estimators': 10}\n",
      "0.88850 (+/-0.03644) for {'max_depth': 100, 'max_features': 2, 'n_estimators': 50}\n",
      "0.88850 (+/-0.02649) for {'max_depth': 100, 'max_features': 2, 'n_estimators': 100}\n",
      "0.88850 (+/-0.03086) for {'max_depth': 100, 'max_features': 3, 'n_estimators': 10}\n",
      "0.89735 (+/-0.01416) for {'max_depth': 100, 'max_features': 3, 'n_estimators': 50}\n",
      "0.89735 (+/-0.01416) for {'max_depth': 100, 'max_features': 3, 'n_estimators': 100}\n",
      "0.89204 (+/-0.04248) for {'max_depth': 100, 'max_features': 4, 'n_estimators': 10}\n",
      "0.89027 (+/-0.02401) for {'max_depth': 100, 'max_features': 4, 'n_estimators': 50}\n",
      "0.89735 (+/-0.02401) for {'max_depth': 100, 'max_features': 4, 'n_estimators': 100}\n",
      "\n",
      "Best parameters set found on train: {'max_depth': 5, 'max_features': 3, 'n_estimators': 10}\n",
      "\n",
      "Best model validation accuracy: 0.9026548672566371\n",
      "(0.0, 0.0, 1.9878964322973283)\n",
      "(0.0, 0.002631578947368421, 0.9878964322973282)\n",
      "(0.0, 0.007894736842105263, 0.984514789785251)\n",
      "(0.0, 0.015789473684210527, 0.9781362260898341)\n",
      "(0.0, 0.02368421052631579, 0.9776943391901465)\n",
      "(0.0, 0.02631578947368421, 0.9767843773685037)\n",
      "(0.0, 0.034210526315789476, 0.9743126966780693)\n",
      "(0.0, 0.09210526315789473, 0.9500084044333386)\n",
      "(0.0, 0.10263157894736842, 0.948988058506702)\n",
      "(0.0, 0.10789473684210527, 0.9479710670659787)\n",
      "(0.0, 0.12368421052631579, 0.9464902597214448)\n",
      "(0.0, 0.14473684210526316, 0.946371520207481)\n",
      "(0.0, 0.15526315789473685, 0.9436926264437385)\n",
      "(0.0, 0.1763157894736842, 0.9425479907957163)\n",
      "(0.0, 0.18421052631578946, 0.9424318284734297)\n",
      "(0.0, 0.19736842105263158, 0.9420121188934081)\n",
      "(0.0, 0.2026315789473684, 0.940519353338448)\n",
      "(0.0, 0.21052631578947367, 0.9400833639193248)\n",
      "(0.0, 0.21578947368421053, 0.9388163047547563)\n",
      "(0.0, 0.22631578947368422, 0.9387315151979945)\n",
      "(0.0, 0.22894736842105262, 0.9374576027321619)\n",
      "(0.0, 0.2394736842105263, 0.9371377108263708)\n",
      "(0.0, 0.24473684210526317, 0.9364262769986127)\n",
      "(0.0, 0.25526315789473686, 0.93625983450756)\n",
      "(0.0, 0.2631578947368421, 0.9361436721852734)\n",
      "(0.0, 0.2710526315789474, 0.9355451275971804)\n",
      "(0.0, 0.27631578947368424, 0.9349079857862298)\n",
      "(0.0, 0.2894736842105263, 0.9313642848051723)\n",
      "(0.0, 0.29473684210526313, 0.9308495545382145)\n",
      "(0.0, 0.30526315789473685, 0.9307229530883256)\n",
      "(0.0, 0.32105263157894737, 0.9278617331044373)\n",
      "(0.0, 0.32894736842105265, 0.926190037068281)\n",
      "(0.0, 0.3394736842105263, 0.9246237890487231)\n",
      "(0.0, 0.3447368421052632, 0.9229171073835867)\n",
      "(0.0, 0.35526315789473684, 0.9203668345885347)\n",
      "(0.0, 0.36578947368421055, 0.9201970325751929)\n",
      "(0.0, 0.3763157894736842, 0.9185486800289441)\n",
      "(0.005405405405405406, 0.3763157894736842, 0.9185028403843871)\n",
      "(0.005405405405405406, 0.37894736842105264, 0.918301722768202)\n",
      "(0.005405405405405406, 0.38421052631578945, 0.917809482119935)\n",
      "(0.005405405405405406, 0.3894736842105263, 0.9164176124527795)\n",
      "(0.005405405405405406, 0.39473684210526316, 0.9160758953463564)\n",
      "(0.005405405405405406, 0.3973684210526316, 0.9157514499731502)\n",
      "(0.010810810810810811, 0.4052631578947368, 0.9147083107706816)\n",
      "(0.010810810810810811, 0.4105263157894737, 0.91439960125182)\n",
      "(0.010810810810810811, 0.43157894736842106, 0.9122605237407878)\n",
      "(0.016216216216216217, 0.4394736842105263, 0.9120135664800457)\n",
      "(0.016216216216216217, 0.45263157894736844, 0.9098457465091405)\n",
      "(0.016216216216216217, 0.4631578947368421, 0.9094409018062745)\n",
      "(0.016216216216216217, 0.4710526315789474, 0.9084771757996568)\n",
      "(0.016216216216216217, 0.48157894736842105, 0.9081900370682809)\n",
      "(0.016216216216216217, 0.48947368421052634, 0.906940250197011)\n",
      "(0.016216216216216217, 0.49473684210526314, 0.9069128361832973)\n",
      "(0.016216216216216217, 0.5026315789473684, 0.9062693173938003)\n",
      "(0.016216216216216217, 0.5078947368421053, 0.9056316840725716)\n",
      "(0.016216216216216217, 0.5184210526315789, 0.9035736318213573)\n",
      "(0.016216216216216217, 0.5263157894736842, 0.9028818189489958)\n",
      "(0.016216216216216217, 0.5368421052631579, 0.9027817766177375)\n",
      "(0.016216216216216217, 0.5421052631578948, 0.9016706259611386)\n",
      "(0.016216216216216217, 0.5473684210526316, 0.9010506084378038)\n",
      "(0.016216216216216217, 0.5552631578947368, 0.8999725923140579)\n",
      "(0.021621621621621623, 0.5868421052631579, 0.8989582472059727)\n",
      "(0.021621621621621623, 0.5947368421052631, 0.8969921771897885)\n",
      "(0.021621621621621623, 0.6, 0.8958978637169585)\n",
      "(0.021621621621621623, 0.6052631578947368, 0.8927049284530273)\n",
      "(0.021621621621621623, 0.6105263157894737, 0.8925950553745684)\n",
      "(0.021621621621621623, 0.6131578947368421, 0.8920340352534296)\n",
      "(0.02702702702702703, 0.6157894736842106, 0.8897496725495454)\n",
      "(0.02702702702702703, 0.6210526315789474, 0.8883184997815793)\n",
      "(0.02702702702702703, 0.6263157894736842, 0.8876816525338711)\n",
      "(0.02702702702702703, 0.6289473684210526, 0.8873464267473228)\n",
      "(0.02702702702702703, 0.6394736842105263, 0.8867381345020341)\n",
      "(0.02702702702702703, 0.65, 0.8851450915724322)\n",
      "(0.02702702702702703, 0.6552631578947369, 0.8843928987033515)\n",
      "(0.032432432432432434, 0.6552631578947369, 0.8838581231221065)\n",
      "(0.032432432432432434, 0.6631578947368421, 0.8816518331149126)\n",
      "(0.032432432432432434, 0.6684210526315789, 0.8812494126975228)\n",
      "(0.032432432432432434, 0.6842105263157895, 0.8763937332130098)\n",
      "(0.03783783783783784, 0.6868421052631579, 0.8754416648425607)\n",
      "(0.03783783783783784, 0.6921052631578948, 0.8749589364392005)\n",
      "(0.03783783783783784, 0.6973684210526315, 0.8742197385301912)\n",
      "(0.03783783783783784, 0.7026315789473684, 0.8721727859994128)\n",
      "(0.03783783783783784, 0.7078947368421052, 0.8718060647276827)\n",
      "(0.03783783783783784, 0.7421052631578947, 0.8558602392627636)\n",
      "(0.03783783783783784, 0.7473684210526316, 0.8552542129016534)\n",
      "(0.03783783783783784, 0.7710526315789473, 0.8474024847513169)\n",
      "(0.03783783783783784, 0.7763157894736842, 0.8458194218817928)\n",
      "(0.03783783783783784, 0.7789473684210526, 0.8440858458892967)\n",
      "(0.043243243243243246, 0.781578947368421, 0.8400135664800457)\n",
      "(0.043243243243243246, 0.8, 0.8305579837746497)\n",
      "(0.04864864864864865, 0.8, 0.8285525469550713)\n",
      "(0.04864864864864865, 0.8342105263157895, 0.8046073306541853)\n",
      "(0.05405405405405406, 0.8342105263157895, 0.8011215304236193)\n",
      "(0.05405405405405406, 0.8368421052631579, 0.800788994236847)\n",
      "(0.05405405405405406, 0.8421052631578947, 0.7989582472059727)\n",
      "(0.05405405405405406, 0.8447368421052631, 0.7985146168888373)\n",
      "(0.05945945945945946, 0.8447368421052631, 0.7984477332931658)\n",
      "(0.05945945945945946, 0.881578947368421, 0.7783429427160815)\n",
      "(0.07027027027027027, 0.881578947368421, 0.7746426015661739)\n",
      "(0.07027027027027027, 0.8894736842105263, 0.7712127379702914)\n",
      "(0.07567567567567568, 0.8894736842105263, 0.7704817288842533)\n",
      "(0.07567567567567568, 0.9, 0.7661349377444522)\n",
      "(0.08108108108108109, 0.9, 0.7659383088567762)\n",
      "(0.08108108108108109, 0.9026315789473685, 0.7658834498834499)\n",
      "(0.08648648648648649, 0.9026315789473685, 0.7654201295178364)\n",
      "(0.08648648648648649, 0.9210526315789473, 0.7574361967009026)\n",
      "(0.0918918918918919, 0.9210526315789473, 0.7566232409790221)\n",
      "(0.0918918918918919, 0.9263157894736842, 0.7548892226752077)\n",
      "(0.0972972972972973, 0.9263157894736842, 0.7527680105539957)\n",
      "(0.0972972972972973, 0.9421052631578948, 0.7373238949765891)\n",
      "(0.10270270270270271, 0.9421052631578948, 0.7342777979465177)\n",
      "(0.10270270270270271, 0.9473684210526315, 0.7252579438105753)\n",
      "(0.10810810810810811, 0.9473684210526315, 0.7245344008740783)\n",
      "(0.11891891891891893, 0.9473684210526315, 0.723341737766672)\n",
      "(0.11891891891891893, 0.9526315789473684, 0.7147376747177346)\n",
      "(0.12432432432432433, 0.9526315789473684, 0.7000693583170838)\n",
      "(0.12432432432432433, 0.9552631578947368, 0.6985719062246003)\n",
      "(0.12972972972972974, 0.9552631578947368, 0.6948782532524735)\n",
      "(0.12972972972972974, 0.9605263157894737, 0.6943488529014845)\n",
      "(0.14054054054054055, 0.9605263157894737, 0.6912127379702914)\n",
      "(0.14054054054054055, 0.968421052631579, 0.6731730084471859)\n",
      "(0.15135135135135136, 0.968421052631579, 0.6673019594025063)\n",
      "(0.15135135135135136, 0.9763157894736842, 0.6325342848872262)\n",
      "(0.15675675675675677, 0.9763157894736842, 0.62917710128472)\n",
      "(0.15675675675675677, 0.9842105263157894, 0.6163824884901072)\n",
      "(0.17297297297297298, 0.9842105263157894, 0.5941339679736453)\n",
      "(0.17297297297297298, 0.9868421052631579, 0.5885004095553967)\n",
      "(0.1837837837837838, 0.9868421052631579, 0.5812664451131944)\n",
      "(0.1837837837837838, 0.9894736842105263, 0.5809622070171943)\n",
      "(0.1891891891891892, 0.9894736842105263, 0.5752949656123031)\n",
      "(0.1891891891891892, 0.9921052631578947, 0.5752579438105754)\n",
      "(0.2, 0.9921052631578947, 0.558682401015402)\n",
      "(0.20540540540540542, 0.9947368421052631, 0.5564700650226967)\n",
      "(0.21621621621621623, 0.9947368421052631, 0.5363824884901074)\n",
      "(0.21621621621621623, 0.9973684210526316, 0.5332021954080778)\n",
      "(0.2648648648648649, 0.9973684210526316, 0.40364403280042477)\n",
      "(0.2648648648648649, 1.0, 0.3890903858783116)\n",
      "(0.32972972972972975, 1.0, 0.15555555555555556)\n",
      "(0.34594594594594597, 1.0, 0.14621821164889254)\n",
      "(0.35135135135135137, 1.0, 0.12837944664031622)\n",
      "(0.40540540540540543, 1.0, 0.12502459177650993)\n",
      "(0.42702702702702705, 1.0, 0.10782608695652174)\n",
      "(0.43783783783783786, 1.0, 0.10565217391304346)\n",
      "(0.4918918918918919, 1.0, 0.10056603773584907)\n",
      "(0.5135135135135135, 1.0, 0.1)\n",
      "(0.518918918918919, 1.0, 0.08365217391304348)\n",
      "(0.6486486486486487, 1.0, 0.07285067873303167)\n",
      "(0.654054054054054, 1.0, 0.063)\n",
      "(0.7567567567567568, 1.0, 0.05565217391304348)\n",
      "(0.7837837837837838, 1.0, 0.05217391304347826)\n",
      "(0.8054054054054054, 1.0, 0.0375)\n",
      "(0.8324324324324325, 1.0, 0.028000000000000004)\n",
      "(0.8486486486486486, 1.0, 0.01)\n",
      "(0.8702702702702703, 1.0, 0.007692307692307693)\n",
      "(0.918918918918919, 1.0, 0.004545454545454545)\n",
      "(1.0, 1.0, 0.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_parms = {'n_estimators':[10, 50,100],'max_features':[2,3,4],'max_depth':[5,10,25,50,100]} \n",
    "\n",
    "RFC = RandomForestClassifier(random_state=123)\n",
    "cv = GridSearchCV(RFC, grid_parms, cv = 5)\n",
    "cv.fit(X_train_sf,y_model_2_train)\n",
    "\n",
    "print('Grid scores for all models based on CV:\\n')\n",
    "means = cv.cv_results_['mean_test_score']\n",
    "stds = cv.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, cv.cv_results_['params']):\n",
    "    print(\"%0.5f (+/-%0.05f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "print('\\nBest parameters set found on train:', cv.best_params_)\n",
    "print('\\nBest model validation accuracy:', cv.best_score_)\n",
    "\n",
    "best_model = cv.best_estimator_\n",
    "\n",
    "y_rf = best_model.predict_proba(X_train_sf)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_model_2_train, y_rf[:,1])\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10, label='threshold zero', fillstyle='none', c='k', mew=2)\n",
    "\n",
    "plt.plot(fpr, tpr, label = 'p r curve')\n",
    "\n",
    "for row in zip(fpr, tpr, thresholds):\n",
    "    print(row)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6974358974358974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.28      0.37       123\n",
      "         1.0       0.73      0.89      0.80       267\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       390\n",
      "   macro avg       0.63      0.59      0.59       390\n",
      "weighted avg       0.67      0.70      0.67       390\n",
      "\n",
      "[[ 35  88]\n",
      " [ 30 237]]\n"
     ]
    }
   ],
   "source": [
    "prediction_rf = best_model.predict(X_test_sf)\n",
    "\n",
    "print(best_model.score(X_test_sf, y_model_2_test))\n",
    "print(classification_report(y_model_2_test, prediction_rf))\n",
    "print(confusion_matrix(y_model_2_test, prediction_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.33      0.40       123\n",
      "         1.0       0.73      0.84      0.78       267\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       390\n",
      "   macro avg       0.61      0.59      0.59       390\n",
      "weighted avg       0.66      0.68      0.66       390\n",
      "\n",
      "[[ 41  82]\n",
      " [ 42 225]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtag_tweet</th>\n",
       "      <th>financial_url</th>\n",
       "      <th>probability</th>\n",
       "      <th>numest</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01432</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.825036</td>\n",
       "      <td>0.03203</td>\n",
       "      <td>0.04297</td>\n",
       "      <td>0.027122</td>\n",
       "      <td>0.049413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cashtag_tweet  financial_url  probability   numest  char_count  word_count  \\\n",
       "0        0.01432       0.009108     0.825036  0.03203     0.04297    0.027122   \n",
       "\n",
       "   word_density  \n",
       "0      0.049413  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs_test = best_model.predict_proba(X_test_sf)\n",
    "y_probs_test = pd.DataFrame(y_probs_test[:,1]).copy(deep=True)\n",
    "\n",
    "y_probs_test['new_pred'] = (y_probs_test >= 0.5885004095553967).astype(int)\n",
    "y_probs_pred_test = y_probs_test['new_pred']\n",
    "\n",
    "print(classification_report(y_model_2_test, y_probs_pred_test))\n",
    "print(confusion_matrix(y_model_2_test, y_probs_pred_test))\n",
    "\n",
    "imp_feat = pd.DataFrame(best_model.feature_importances_).transpose()\n",
    "imp_feat.columns = X_test_sf.columns\n",
    "imp_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try and add Twitter Sentiment from TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.7500000000000001, subjectivity=0.9)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "TextBlob('This is an AMAZING pair of Jeans!').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_snt_obj = X_train_text['clean_text'].apply(lambda row: TextBlob(row).sentiment)\n",
    "X_train_text['Polarity'] = [obj.polarity for obj in X_train_snt_obj.values]\n",
    "X_train_text['Subjectivity'] = [obj.subjectivity for obj in X_train_snt_obj.values]\n",
    "X_train_text_snt = X_train_text.drop(columns=['clean_text'])\n",
    "\n",
    "X_test_snt_obj = X_test_text['clean_text'].apply(lambda row: TextBlob(row).sentiment)\n",
    "X_test_text['Polarity'] = [obj.polarity for obj in X_test_snt_obj.values]\n",
    "X_test_text['Subjectivity'] = [obj.subjectivity for obj in X_test_snt_obj.values]\n",
    "X_test_text_snt = X_test_text.drop(columns=['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta2_s = pd.concat([X_prob_train, X_train_meta,y_train, X_train_text_snt], axis=1)\n",
    "X_model_2_train_s = X_train_meta2_s.groupby(['ticker','actual_dt_e'], as_index=False).agg({'probability':'mean', 'Polarity':'mean', \\\n",
    "                                                                                'Subjectivity':'mean', 'cashtag_tweet':'mean', \\\n",
    "                                                                                'financial_url':'mean', 'numest':'max', \\\n",
    "                                                                                'char_count':'mean', 'word_count':'mean', \\\n",
    "                                                                                'word_density':'mean','eps_beat':'max'})\n",
    "y_model_2_train_s = X_model_2_train_s['eps_beat']\n",
    "X_model_2_train_s = X_model_2_train_s.drop(columns=['eps_beat','actual_dt_e','ticker'])\n",
    "\n",
    "\n",
    "X_test_meta2_s = pd.concat([X_prob_test, X_test_meta,y_test,X_test_text_snt], axis=1)\n",
    "X_model_2_test_s = X_test_meta2_s.groupby(['ticker','actual_dt_e'], as_index=False).agg({'probability':'mean', 'Polarity':'mean', \\\n",
    "                                                                                'Subjectivity':'mean', 'cashtag_tweet':'mean', \\\n",
    "                                                                                'financial_url':'mean', 'numest':'max', \\\n",
    "                                                                                'char_count':'mean', 'word_count':'mean', \\\n",
    "                                                                                'word_density':'mean','eps_beat':'max'})\n",
    "y_model_2_test_s = X_model_2_test_s['eps_beat']\n",
    "X_model_2_test_s = X_model_2_test_s.drop(columns=['eps_beat','actual_dt_e','ticker'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores for all models based on CV:\n",
      "\n",
      "0.32743 (+/-0.00000) for {'C': 0.0001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.0001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.53805 (+/-0.13498) for {'C': 0.0001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.53097 (+/-0.12615) for {'C': 0.0001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.32743 (+/-0.00000) for {'C': 0.0001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.0001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.0001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.0001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.32743 (+/-0.00000) for {'C': 0.001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.60354 (+/-0.27611) for {'C': 0.001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.55929 (+/-0.16121) for {'C': 0.001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.55929 (+/-0.16121) for {'C': 0.001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.56460 (+/-0.18202) for {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.52743 (+/-0.11059) for {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.71681 (+/-0.23454) for {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.71681 (+/-0.22749) for {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.01, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.01, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.01, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.67257 (+/-0.00000) for {'C': 0.01, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89735 (+/-0.07476) for {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89735 (+/-0.07476) for {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89204 (+/-0.06070) for {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89027 (+/-0.06584) for {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.87611 (+/-0.06622) for {'C': 0.1, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.87788 (+/-0.06469) for {'C': 0.1, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.84248 (+/-0.06469) for {'C': 0.1, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.83894 (+/-0.05642) for {'C': 0.1, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.90088 (+/-0.05859) for {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.90265 (+/-0.05484) for {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89735 (+/-0.05081) for {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89558 (+/-0.05859) for {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89558 (+/-0.07202) for {'C': 0.5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89204 (+/-0.07026) for {'C': 0.5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.88673 (+/-0.06469) for {'C': 0.5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.88142 (+/-0.06772) for {'C': 0.5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89558 (+/-0.05529) for {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.90265 (+/-0.05006) for {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.90088 (+/-0.06273) for {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89558 (+/-0.05529) for {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89735 (+/-0.06772) for {'C': 0.75, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89204 (+/-0.07026) for {'C': 0.75, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89204 (+/-0.06565) for {'C': 0.75, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.88673 (+/-0.06172) for {'C': 0.75, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89381 (+/-0.05817) for {'C': 0.99, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.90088 (+/-0.05298) for {'C': 0.99, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.90088 (+/-0.05415) for {'C': 0.99, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89735 (+/-0.06090) for {'C': 0.99, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.89912 (+/-0.07220) for {'C': 0.99, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89381 (+/-0.07425) for {'C': 0.99, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89204 (+/-0.06565) for {'C': 0.99, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.88850 (+/-0.06584) for {'C': 0.99, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.88850 (+/-0.06391) for {'C': 2, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89735 (+/-0.05081) for {'C': 2, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.90088 (+/-0.05298) for {'C': 2, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89735 (+/-0.07133) for {'C': 2, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.90265 (+/-0.05368) for {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89381 (+/-0.07425) for {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89558 (+/-0.07289) for {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89204 (+/-0.06565) for {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.88142 (+/-0.05986) for {'C': 5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89735 (+/-0.05081) for {'C': 5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.89558 (+/-0.06372) for {'C': 5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89381 (+/-0.06028) for {'C': 5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.90973 (+/-0.04930) for {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.89558 (+/-0.07026) for {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.90088 (+/-0.06172) for {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.89204 (+/-0.06565) for {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "\n",
      "Best parameters set found on train: {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n",
      "Best model validation accuracy: 0.9097345132743363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1abce0e80f0>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "grid_params = {'penalty':['l1','l2'], 'C':[0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 0.99, 2, 5], 'solver':['liblinear','saga'], \\\n",
    "              'max_iter':[10000], 'class_weight':['balanced',None]}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "cv_lr = GridSearchCV(lr, grid_params, cv = 5)\n",
    "\n",
    "cv_lr.fit(X_model_2_train_s,y_model_2_train_s)\n",
    "\n",
    "print('Grid scores for all models based on CV:\\n')\n",
    "means = cv_lr.cv_results_['mean_test_score']\n",
    "stds = cv_lr.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, cv_lr.cv_results_['params']):\n",
    "    print(\"%0.5f (+/-%0.05f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "print('\\nBest parameters set found on train:', cv_lr.best_params_)\n",
    "print('\\nBest model validation accuracy:', cv_lr.best_score_)\n",
    "\n",
    "best_model = cv_lr.best_estimator_\n",
    "\n",
    "y_lr = best_model.predict_proba(X_model_2_train_s)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_model_2_train_s, y_lr[:,1])\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10, label='threshold zero', fillstyle='none', c='k', mew=2)\n",
    "\n",
    "plt.plot(fpr, tpr, label = 'p r curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0, 1.9923141458080396)\n",
      "(0.0, 0.002631578947368421, 0.9923141458080396)\n",
      "(0.0, 0.07368421052631578, 0.9757614287540389)\n",
      "(0.005405405405405406, 0.07368421052631578, 0.9755074559931337)\n",
      "(0.005405405405405406, 0.09736842105263158, 0.9713651439532787)\n",
      "(0.010810810810810811, 0.09736842105263158, 0.9713517063760241)\n",
      "(0.010810810810810811, 0.11052631578947368, 0.9699055546257783)\n",
      "(0.010810810810810811, 0.11578947368421053, 0.9693562799304156)\n",
      "(0.010810810810810811, 0.13421052631578947, 0.9681749259981178)\n",
      "(0.016216216216216217, 0.13421052631578947, 0.9680463839718216)\n",
      "(0.016216216216216217, 0.1631578947368421, 0.9648497316618855)\n",
      "(0.021621621621621623, 0.1631578947368421, 0.9640308632018194)\n",
      "(0.021621621621621623, 0.2710526315789474, 0.9504747757431269)\n",
      "(0.02702702702702703, 0.2710526315789474, 0.9502947531711955)\n",
      "(0.02702702702702703, 0.30526315789473685, 0.9465782620165913)\n",
      "(0.032432432432432434, 0.30526315789473685, 0.9453656277795293)\n",
      "(0.032432432432432434, 0.35789473684210527, 0.9409129710517995)\n",
      "(0.03783783783783784, 0.35789473684210527, 0.9389775577277178)\n",
      "(0.03783783783783784, 0.3973684210526316, 0.934140681051006)\n",
      "(0.043243243243243246, 0.3973684210526316, 0.9329448690470833)\n",
      "(0.043243243243243246, 0.4026315789473684, 0.932791050780651)\n",
      "(0.043243243243243246, 0.4105263157894737, 0.9324890611106272)\n",
      "(0.043243243243243246, 0.45, 0.9247583511439106)\n",
      "(0.04864864864864865, 0.45, 0.9246634530660913)\n",
      "(0.04864864864864865, 0.46578947368421053, 0.9228658371988695)\n",
      "(0.05405405405405406, 0.46578947368421053, 0.9227934530206342)\n",
      "(0.05405405405405406, 0.48947368421052634, 0.9178960742202135)\n",
      "(0.05945945945945946, 0.48947368421052634, 0.9178889261329576)\n",
      "(0.05945945945945946, 0.4921052631578947, 0.9173312736499981)\n",
      "(0.06486486486486487, 0.4921052631578947, 0.9162340270158752)\n",
      "(0.06486486486486487, 0.5078947368421053, 0.9144414392919142)\n",
      "(0.06486486486486487, 0.5131578947368421, 0.9144002474787067)\n",
      "(0.06486486486486487, 0.6, 0.9014530180401605)\n",
      "(0.07027027027027027, 0.6, 0.9014125974961342)\n",
      "(0.07027027027027027, 0.6342105263157894, 0.894947539308775)\n",
      "(0.07567567567567568, 0.6342105263157894, 0.8943888109607269)\n",
      "(0.07567567567567568, 0.6368421052631579, 0.894111757464279)\n",
      "(0.08108108108108109, 0.6368421052631579, 0.8939933503551608)\n",
      "(0.08108108108108109, 0.6473684210526316, 0.8900284969390355)\n",
      "(0.08648648648648649, 0.6473684210526316, 0.8890069236462829)\n",
      "(0.08648648648648649, 0.6578947368421053, 0.8864604572696491)\n",
      "(0.0918918918918919, 0.6578947368421053, 0.8861359251073755)\n",
      "(0.0918918918918919, 0.6973684210526315, 0.8758001386826756)\n",
      "(0.0972972972972973, 0.6973684210526315, 0.8748509047979669)\n",
      "(0.0972972972972973, 0.718421052631579, 0.8702086078401516)\n",
      "(0.10270270270270271, 0.718421052631579, 0.8701630162730853)\n",
      "(0.10270270270270271, 0.7289473684210527, 0.8657313928841651)\n",
      "(0.10810810810810811, 0.7289473684210527, 0.8652066093555392)\n",
      "(0.10810810810810811, 0.7894736842105263, 0.8422687856893856)\n",
      "(0.11351351351351352, 0.7894736842105263, 0.8408146533498018)\n",
      "(0.11351351351351352, 0.7921052631578948, 0.8394428132261168)\n",
      "(0.11891891891891893, 0.7921052631578948, 0.8388054553445607)\n",
      "(0.11891891891891893, 0.7973684210526316, 0.8369728484466701)\n",
      "(0.12432432432432433, 0.7973684210526316, 0.8364962675138445)\n",
      "(0.12432432432432433, 0.8289473684210527, 0.8246946686643095)\n",
      "(0.12972972972972974, 0.8289473684210527, 0.8227831325349887)\n",
      "(0.12972972972972974, 0.8315789473684211, 0.8183279636836177)\n",
      "(0.13513513513513514, 0.8315789473684211, 0.8156393795632007)\n",
      "(0.13513513513513514, 0.8605263157894737, 0.802456627936985)\n",
      "(0.14594594594594595, 0.8605263157894737, 0.7984292915279245)\n",
      "(0.14594594594594595, 0.8763157894736842, 0.7878146519007716)\n",
      "(0.15135135135135136, 0.8763157894736842, 0.7870006950989369)\n",
      "(0.15135135135135136, 0.881578947368421, 0.7846700632350205)\n",
      "(0.15675675675675677, 0.881578947368421, 0.7832331227641414)\n",
      "(0.15675675675675677, 0.8868421052631579, 0.7807976324793439)\n",
      "(0.16756756756756758, 0.8868421052631579, 0.776725460373567)\n",
      "(0.16756756756756758, 0.9236842105263158, 0.7531612853857743)\n",
      "(0.17297297297297298, 0.9236842105263158, 0.7528434014031723)\n",
      "(0.17297297297297298, 0.9289473684210526, 0.7442717050882314)\n",
      "(0.1783783783783784, 0.9289473684210526, 0.7427670238539902)\n",
      "(0.1783783783783784, 0.9342105263157895, 0.7279709600886807)\n",
      "(0.1945945945945946, 0.9342105263157895, 0.7207700095199386)\n",
      "(0.1945945945945946, 0.9421052631578948, 0.7006330847063675)\n",
      "(0.2, 0.9421052631578948, 0.6970627714386355)\n",
      "(0.2, 0.9526315789473684, 0.6887433891138196)\n",
      "(0.20540540540540542, 0.9526315789473684, 0.6863697437185067)\n",
      "(0.20540540540540542, 0.9578947368421052, 0.6703907094305582)\n",
      "(0.21081081081081082, 0.9578947368421052, 0.6611443699847481)\n",
      "(0.21081081081081082, 0.968421052631579, 0.645639279440885)\n",
      "(0.21621621621621623, 0.968421052631579, 0.6437775262324695)\n",
      "(0.21621621621621623, 0.9710526315789474, 0.6371716065520374)\n",
      "(0.22162162162162163, 0.9710526315789474, 0.6351620283279839)\n",
      "(0.22162162162162163, 0.9736842105263158, 0.6280841310382911)\n",
      "(0.22702702702702704, 0.9736842105263158, 0.620682952371395)\n",
      "(0.22702702702702704, 0.9789473684210527, 0.5926171710587043)\n",
      "(0.23243243243243245, 0.9789473684210527, 0.5783723786250794)\n",
      "(0.23243243243243245, 0.9921052631578947, 0.5573696059974674)\n",
      "(0.23783783783783785, 0.9921052631578947, 0.5390122710452829)\n",
      "(0.23783783783783785, 0.9947368421052631, 0.5352745135847475)\n",
      "(0.2810810810810811, 0.9947368421052631, 0.43111174320353)\n",
      "(0.2810810810810811, 0.9973684210526316, 0.4169098793526312)\n",
      "(0.2864864864864865, 0.9973684210526316, 0.41644037691673674)\n",
      "(0.2864864864864865, 1.0, 0.3963090725528205)\n",
      "(1.0, 1.0, 1.536458102349076e-07)\n"
     ]
    }
   ],
   "source": [
    "for row in zip(fpr, tpr, thresholds):\n",
    "    print(row)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  44]\n",
      " [  2 378]]\n"
     ]
    }
   ],
   "source": [
    "y_probs = pd.DataFrame(y_lr[:,1]).copy(deep=True)\n",
    "y_probs['new_pred'] = (y_probs >= 0.52).astype(int)\n",
    "y_probs_pred = y_probs['new_pred']\n",
    "\n",
    "print(confusion_matrix(y_model_2_train_s, y_probs_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6974358974358974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.32      0.40       123\n",
      "         1.0       0.74      0.87      0.80       267\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       390\n",
      "   macro avg       0.63      0.59      0.60       390\n",
      "weighted avg       0.67      0.70      0.67       390\n",
      "\n",
      "[[ 39  84]\n",
      " [ 34 233]]\n",
      "   probability  Polarity  Subjectivity  cashtag_tweet  financial_url  \\\n",
      "0    17.217165 -1.071212      0.839967      -0.619774      -1.586806   \n",
      "\n",
      "     numest  char_count  word_count  word_density  \n",
      "0  0.016965    0.057242   -0.508101      -0.13777  \n"
     ]
    }
   ],
   "source": [
    "prediction_lr = best_model.predict(X_model_2_test_s)\n",
    "\n",
    "print(best_model.score(X_model_2_test_s, y_model_2_test_s))\n",
    "print(classification_report(y_model_2_test_s, prediction_lr))\n",
    "print(confusion_matrix(y_model_2_test_s, prediction_lr))\n",
    "print(pd.DataFrame(best_model.coef_.tolist(),columns=X_model_2_test_s.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6974358974358974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.32      0.39       123\n",
      "         1.0       0.73      0.87      0.79       267\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       390\n",
      "   macro avg       0.63      0.59      0.59       390\n",
      "weighted avg       0.67      0.69      0.67       390\n",
      "\n",
      "[[ 39  84]\n",
      " [ 36 231]]\n"
     ]
    }
   ],
   "source": [
    "y_probs_test = best_model.predict_proba(X_model_2_test_s)\n",
    "y_probs_test = pd.DataFrame(y_probs_test[:,1]).copy(deep=True)\n",
    "\n",
    "y_probs_test['new_pred'] = (y_probs_test >= 0.52).astype(int)\n",
    "y_probs_pred_test = y_probs_test['new_pred']\n",
    "\n",
    "print(best_model.score(X_model_2_test_s, y_model_2_test_s))\n",
    "print(classification_report(y_model_2_test_s, y_probs_pred_test))\n",
    "print(confusion_matrix(y_model_2_test_s, y_probs_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Results Summary\n",
    "\n",
    "Overall I would say that using just information gained from Twitter activity does not provide a large improvement over just selecting all observations as 1 (Beat EPS), as ~70% of my total observations are values of 1. I am on average able to get about 70% accuracy, with the majority of my correct predictions coming from the 'Beat EPS' observations. One potential downfall of this approach is that we do not observe the impact of not Tweeting in this sample of firm earnings announcement. In other words, it might be that a firm only tweets when they have something positive to tweet about. To further the value of this project, it would be nice to have all earnings announcements and see the impact of Twitter characteristics rather than just focusing on the earnings announcements that also have Twitter activity.\n",
    "\n",
    "Other possible extensions include changing my analysis from averaging the probabilities of an EPS beat across each firm-announcement observations to concatenating all tweets within each firm-announcement observations and running the analysis this way. Considering the impact of the following may provide additional insights as well:\n",
    "    - tfvid\n",
    "    - Word2Vec\n",
    "    - FastText\n",
    "    - Some form of pretrained text\n",
    "    - Considering the tweet text characteristics on the uncleaned text rather than the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     pg say good start fiscal year continue top line momentum profitable market share growth\n",
       "1                                                                                 report first quarter result\n",
       "2               cokeceo highlight clear system vision strong brand solid execution driver quality q result jm\n",
       "3          weall focus increase north america share key vertical improve performance like staffing technology\n",
       "4                                                          chevron announce quarterly dividend stock dividend\n",
       "5                      first quarter gaap operating profit billion gaap dilute earning per share year earlier\n",
       "6                                                           polycom report fourth quarter fiscal year earning\n",
       "7                                                           live webcast full year result begin ct friday jan\n",
       "8                                                                                       release q fy guidance\n",
       "9                    horizon present datum demonstrating rayos reduce morning stiffness patient active ra acr\n",
       "10                                                   positive driver growth long one detractor growth earning\n",
       "11                                           wall street journal select allergan cfo jeff edward one top cfos\n",
       "12                                                           concur report strong result third quarter fiscal\n",
       "13             cokeceo pleased ko system represent non alcoholic ready drink total industry growth billion mp\n",
       "14                                                                      q engagement grow average reach march\n",
       "15                                           announce today record revenue nd quarter mil generate mil income\n",
       "16                                                  gold price affect jewelry sale bluenile ceo harvey kanter\n",
       "17                                                            gp strategy report second quarter result august\n",
       "18                                                       great earning recap rt yahoo top revenue lead profit\n",
       "19                               marketing solution revenue grow yoy represent total revenue compare yr ago q\n",
       "20                                            not forget join q earning call friday july est full detail gold\n",
       "21                                             not worry free version remain free ceo record earning call say\n",
       "22                                             watch exclusive video interview ceo selina lo wifi smallcell g\n",
       "23                                                                                 drilling success rate read\n",
       "24                                                            navigate healthcarereform resource ceo smallbiz\n",
       "25                                                chevron announce increase quarterly dividend stock dividend\n",
       "26                                                cfos say company focus pursue opportunity limit risk survey\n",
       "27                           launch yoplait simplait line great tasting natural yogurt simple ingredient gisf\n",
       "28                beknown launch simultaneously country language steadily gain member w mobile version plan q\n",
       "29                                            compliance risk officer kelly service banking financial service\n",
       "                                                        ...                                                  \n",
       "816                                                      release newmont declare quarterly dividend per share\n",
       "817                                                      july sale sonic retail sale leader segment since apr\n",
       "818                microsoft earning enterprise demand fuel continue growth significant product launch aheada\n",
       "819                                     aerovironment nd quarter fiscal earning release conf call today pm pt\n",
       "820                 walmart president ceo mike duke join top ceo federal deficit discussion w president obama\n",
       "821                                                    watch honeywell ceo dave cote speech chamberofcommerce\n",
       "822                                         juniper network report preliminary first quarter financial result\n",
       "823    linkedin head product david hahn provide overview product roadmap w implication financial service infc\n",
       "824                              report first quarter result tomorrow may via conference call est information\n",
       "825                                                                 cubist host q earning webcast today pm et\n",
       "826                                                campbell ceo denise morrison barron ceo spotlight attitude\n",
       "827                            cboe holding inc announce share repurchase program increase quarterly dividend\n",
       "828                                                        domino rd quarter result listen earning webcast et\n",
       "829                                                                yahoo q xenoport inc earning release pm et\n",
       "830                             cfo john gerspach review q earning report live webcast teleconference et info\n",
       "831                 ceo mike jackson say expect sale q equal surpass continue see solid recovery move forward\n",
       "832                                                              join us pm pt result call live tweet earning\n",
       "833                           john hartley win last award night large company cfo year congratulation john nv\n",
       "834                    cfo magazine profile exelis cfo peter milligan take finance defense aerospace industry\n",
       "835                                          prgs team help accelerate revenue monetize app grow biz new blog\n",
       "836                                  tomorrow live tweet fourth quarter year end earning call join us earning\n",
       "837                                           mcneil share estimate total share quarter point year ago gmsale\n",
       "838             first quarter report billion usd operate income reflect solid worldwide volume growth earning\n",
       "839                                                       euro verge financial panic risk appetite still hold\n",
       "840                                                              live webcast q result begin cdt friday april\n",
       "841                                                                        unisys announce q financial result\n",
       "842                                                                     first solar earning webcast begin edt\n",
       "843                                    estimate fy revenue appx billion billion prev estimate billion billion\n",
       "844                                              emc report record fourth quarter full year revenue profit km\n",
       "845                                                                 msci launch new barra europe equity model\n",
       "Name: clean_text, Length: 846, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'earning': ['fy', 'oracle', 'corp', 'conf', 'january'],\n",
       " 'revenue': ['total', 'billion', 'growth', 'overall', 'dilute'],\n",
       " 'gold': ['hurd', 'fda', 'boss', 'emcforum', 'felixhernandez'],\n",
       " 'fiscal': ['quarter', 'fourth', 'report', 'third', 'second'],\n",
       " 'cfo': ['tn', 'fun', 'amy', 'photo', 'word']}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "tokenized_corpus_train = [wpt.tokenize(document) for document in X_train_text['clean_text']]\n",
    "tokenized_corpus_test = [wpt.tokenize(document) for document in X_test_text['clean_text']]\n",
    "\n",
    "# Set values for various parameters\n",
    "feature_size = 100    # Word vector dimensionality  \n",
    "window_context = 30          # Context window size                                                                                    \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "sample = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "w2v_model = word2vec.Word2Vec(tokenized_corpus_train, size=feature_size, \n",
    "                          window=window_context, min_count=min_word_count,\n",
    "                          sample=sample, iter=50)\n",
    "\n",
    "# view similar words based on gensim's model\n",
    "similar_words = {search_term: [item[0] for item in w2v_model.wv.most_similar([search_term], topn=5)]\n",
    "                  for search_term in ['earning','revenue','gold','fiscal','cfo']}\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jstar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector\n",
    "    \n",
    "   \n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# get document level embeddings\n",
    "w2v_feature_array_train = averaged_word_vectorizer(corpus=tokenized_corpus_train, model=w2v_model,\n",
    "                                             num_features=feature_size)\n",
    "w2v_feature_array_test = averaged_word_vectorizer(corpus=tokenized_corpus_test, model=w2v_model,\n",
    "                                             num_features=feature_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to ask...\n",
    "\n",
    "### word to vec gives a vector of each word, but we need a vector of each document...is that why we average word vectors by doc?\n",
    "\n",
    "    - We don't do this for count_Vectorizer, so why do we do it for word2vec?\n",
    "        - is it just taking the 1 number (Count_Vectorizer) and dividing it into 100 numbers?\n",
    "    - word2vec has negative numbers but nmb can't deal with negative...how to fix?\n",
    "    - doc2vec as simplified word2vec aggegration across doc?\n",
    "   \n",
    "\n",
    "### do we 'fit_transform' on the train and test data with word2vec or just fit_transform on train and transform on test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((846, 100), (846,))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_feature_array.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jstar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores for all models based on CV:\n",
      "\n",
      "0.31678 (+/-0.00212) for {'C': 0.0001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.39007 (+/-0.29315) for {'C': 0.0001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.43972 (+/-0.27559) for {'C': 0.0001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.46927 (+/-0.07988) for {'C': 0.0001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.31678 (+/-0.00212) for {'C': 0.0001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.0001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.0001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.0001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.31678 (+/-0.00212) for {'C': 0.001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.31678 (+/-0.00212) for {'C': 0.001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.47045 (+/-0.11792) for {'C': 0.001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.46809 (+/-0.07532) for {'C': 0.001, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.31678 (+/-0.00212) for {'C': 0.001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.001, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.31678 (+/-0.00212) for {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.53664 (+/-0.35903) for {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.47400 (+/-0.02302) for {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.48345 (+/-0.04324) for {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.01, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.01, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.01, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.01, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.31678 (+/-0.00212) for {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.46336 (+/-0.35903) for {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.48700 (+/-0.04709) for {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.48463 (+/-0.05690) for {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.1, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.1, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.68794 (+/-0.00958) for {'C': 0.1, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.68913 (+/-0.01395) for {'C': 0.1, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.49173 (+/-0.02859) for {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.48582 (+/-0.04723) for {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.49409 (+/-0.06037) for {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.49527 (+/-0.05723) for {'C': 0.5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.68322 (+/-0.00212) for {'C': 0.5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.68558 (+/-0.00463) for {'C': 0.5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.68913 (+/-0.02097) for {'C': 0.5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.69031 (+/-0.01850) for {'C': 0.5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.49173 (+/-0.01204) for {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.48582 (+/-0.04470) for {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.50591 (+/-0.07730) for {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.50946 (+/-0.07824) for {'C': 0.75, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.68794 (+/-0.00958) for {'C': 0.75, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.68794 (+/-0.01676) for {'C': 0.75, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.69031 (+/-0.01850) for {'C': 0.75, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.69031 (+/-0.01850) for {'C': 0.75, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.49054 (+/-0.03045) for {'C': 0.99, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.48936 (+/-0.03851) for {'C': 0.99, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.51182 (+/-0.07468) for {'C': 0.99, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.51300 (+/-0.07557) for {'C': 0.99, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.69031 (+/-0.01850) for {'C': 0.99, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.69031 (+/-0.01850) for {'C': 0.99, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.69031 (+/-0.01850) for {'C': 0.99, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.69031 (+/-0.01850) for {'C': 0.99, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.50473 (+/-0.05616) for {'C': 2, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.50355 (+/-0.05479) for {'C': 2, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.52955 (+/-0.07888) for {'C': 2, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.53073 (+/-0.07541) for {'C': 2, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.69149 (+/-0.01701) for {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.69031 (+/-0.01850) for {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.69031 (+/-0.01850) for {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.69031 (+/-0.01850) for {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.54019 (+/-0.03090) for {'C': 5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.54019 (+/-0.03944) for {'C': 5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.53783 (+/-0.06760) for {'C': 5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.53783 (+/-0.06760) for {'C': 5, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.68203 (+/-0.03237) for {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.68203 (+/-0.03237) for {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.68440 (+/-0.02641) for {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.68322 (+/-0.02819) for {'C': 5, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "\n",
      "Best parameters set found on train: {'C': 2, 'class_weight': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n",
      "Best model validation accuracy: 0.6914893617021277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1abce634208>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_params = {'penalty':['l1','l2'], 'C':[0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 0.99, 2, 5], 'solver':['liblinear','saga'], \\\n",
    "              'max_iter':[10000], 'class_weight':['balanced',None]}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "cv_lr = GridSearchCV(lr, grid_params, cv = 5)\n",
    "\n",
    "cv_lr.fit(w2v_feature_array,y_train)\n",
    "\n",
    "print('Grid scores for all models based on CV:\\n')\n",
    "means = cv_lr.cv_results_['mean_test_score']\n",
    "stds = cv_lr.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, cv_lr.cv_results_['params']):\n",
    "    print(\"%0.5f (+/-%0.05f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "print('\\nBest parameters set found on train:', cv_lr.best_params_)\n",
    "print('\\nBest model validation accuracy:', cv_lr.best_score_)\n",
    "\n",
    "best_model = cv_lr.best_estimator_\n",
    "\n",
    "y_lr = best_model.predict_proba(w2v_feature_array)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_lr[:,1])\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10, label='threshold zero', fillstyle='none', c='k', mew=2)\n",
    "\n",
    "plt.plot(fpr, tpr, label = 'p r curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does this comment mean?\n",
    "\n",
    "Last year, I followed Prof: Andrew Ng’s online machine learning course. His recommendation was\n",
    "\n",
    "Training: 60%\n",
    "\n",
    "Cross validation: 20%\n",
    "\n",
    "Testing: 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consider a tfvid model\n",
    "\n",
    "# Word2Vec next\n",
    "# FastText? - try to approximates by ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####TRAIN TEST SPLIT ON ACTUAL DATA, NOT THE COUNT VECTORIZED DATA\n",
    "    ####TRAIN ONLY ON THE TRAINNG DATA, MODEL SHOULD NOT KNOW THE NEW WORDS THAT APPEAR IN THE TEST DATA ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "####100 ORIGINAL OBS\n",
    "#####TRAIN MODEL MNB (50%, 50/50)\n",
    "    ####GET PROBABILITIES ON TEST AND TRAIN (50/50)\n",
    "            ####MERGE PROB BACK INTO MODEL 1 TRAIN AND TEST DATA SETS (50/50)\n",
    "                    #####RETAIN EXACT SAME SPLITS AS THE ORIGINAL MODEL TRAIN TEST SPLIT (50/50) - MODEL 2\n",
    "            \n",
    "#####train,test = split(df.index.values, actual labels)\n",
    "    #####train_idx, test_idx - after fitting model and getting probabilities, merge back to original data and retest second\n",
    "    #####stage model using same train test split sample while now including the probabilities\n",
    "#####Split data first, then count vectorize each X_test, X_train separately\n",
    "#####train_df = df.iloc[train_idx]\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
